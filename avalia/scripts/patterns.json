[
  {
    "url": "https://glossary.cncf.io/zero-trust-architecture",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/zero-trust-architecture.md",
    "title": "Zero Trust Architecture",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "security"
    ],
    "markdown": "## What it is\n\nZero trust architecture prescribes to an approach to the design and implementation of IT systems \nwhere trust is completely removed. \nThe core principle being \"never trust, always verify\", devices or systems themselves, \nwhilst communicating to other components of a system, always verify themselves before doing so. \nIn many networks today, within the corporate network, systems and devices inside may freely communicate with each other \nas they are within the trusted boundary of the corporate network perimeter. \nZero trust architecture takes the opposite approach where although inside the network perimeter, \ncomponents within the system first have to pass verification before any communication is made.\n\n## Problem it addresses\n\nWith the traditional trust based approach where systems and devices that exist within a corporate network perimeter, \nthe assumption is that because there is trust, there is no problem. \nZero trust architecture however, recognises that trust is a vulnerability. \nIn the event where an attacker has gained access to a trusted device, \ndepending on the level of trust and access that has been given to that device, \nthe system is now vulnerable to attack \nas the attacker is within the \"trusted\" network perimeter and is able to move laterally throughout the system. \nIn a zero trust architecture, trust is removed, therefore reducing the attack surface \nas an attacker is now forced to verify before going any further throughout the system.\n\n## How it helps\n\nAdopting a zero trust architecture brings the principal benefit of increased security \nwith a reduction in the attack surface. \nRemoving trust from your corporate system now increases the number and strength of security gates \nthat an attacker has to go through to gain access to other areas of the system.\n",
    "what_it_is": "Zero trust architecture prescribes to an approach to the design and implementation of IT systems \nwhere trust is completely removed. \nThe core principle being \"never trust, always verify\", devices or systems themselves, \nwhilst communicating to other components of a system, always verify themselves before doing so. \nIn many networks today, within the corporate network, systems and devices inside may freely communicate with each other \nas they are within the trusted boundary of the corporate network perimeter. \nZero trust architecture takes the opposite approach where although inside the network perimeter, \ncomponents within the system first have to pass verification before any communication is made.",
    "problem_it_addresses": "With the traditional trust based approach where systems and devices that exist within a corporate network perimeter, \nthe assumption is that because there is trust, there is no problem. \nZero trust architecture however, recognises that trust is a vulnerability. \nIn the event where an attacker has gained access to a trusted device, \ndepending on the level of trust and access that has been given to that device, \nthe system is now vulnerable to attack \nas the attacker is within the \"trusted\" network perimeter and is able to move laterally throughout the system. \nIn a zero trust architecture, trust is removed, therefore reducing the attack surface \nas an attacker is now forced to verify before going any further throughout the system.",
    "how_it_helps": "Adopting a zero trust architecture brings the principal benefit of increased security \nwith a reduction in the attack surface. \nRemoving trust from your corporate system now increases the number and strength of security gates \nthat an attacker has to go through to gain access to other areas of the system.",
    "slug": "zero-trust-architecture"
  },
  {
    "url": "https://glossary.cncf.io/virtualization",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/virtualization.md",
    "title": "Virtualization",
    "status": "completed",
    "category": "technology",
    "tags": [
      "fundamental",
      "infrastructure",
      "methodology"
    ],
    "markdown": "## What it is\n\nVirtualization, in the context of cloud native computing, \nrefers to the process of taking a physical computer, sometimes called a server, \nand allowing it to run multiple isolated operating systems. \nThose isolated operating systems and their dedicated compute resources (CPU, memory, and network) are \nreferred to as virtual machines or VMs. \nWhen we talk about a [virtual machine](https://glossary.cncf.io/virtual-machine/), we’re talking about a software-defined computer. \nSomething that looks and acts like a real computer but is sharing hardware with other virtual machines.\n[Cloud computing](https://glossary.cncf.io/cloud-computing/) is primarily powered by virtualization technology.\nAs an example, you can lease a \"computer\" from AWS – that computer is actually a VM.\n\n## Problem it addresses\n\nVirtualization addresses a number of problems, including the improvement of physical hardware usage \nby allowing more apps to run on the same physical machine \nwhilst still being isolated from each other for security.\n\n## How it helps\n\nApps running on virtual machines have no awareness that they are sharing a physical computer. \nVirtualization also allows the users of the datacenter to spin up a new \"computer\" (aka a VM) in minutes \nwithout worrying about the physical constraints of adding a new computer to a datacenter. \nVMs also enable users to speed up the time to get a new virtual computer.\n",
    "what_it_is": "Virtualization, in the context of cloud native computing, \nrefers to the process of taking a physical computer, sometimes called a server, \nand allowing it to run multiple isolated operating systems. \nThose isolated operating systems and their dedicated compute resources (CPU, memory, and network) are \nreferred to as virtual machines or VMs. \nWhen we talk about a [virtual machine](https://glossary.cncf.io/virtual-machine/), we’re talking about a software-defined computer. \nSomething that looks and acts like a real computer but is sharing hardware with other virtual machines.\n[Cloud computing](https://glossary.cncf.io/cloud-computing/) is primarily powered by virtualization technology.\nAs an example, you can lease a \"computer\" from AWS – that computer is actually a VM.",
    "problem_it_addresses": "Virtualization addresses a number of problems, including the improvement of physical hardware usage \nby allowing more apps to run on the same physical machine \nwhilst still being isolated from each other for security.",
    "how_it_helps": "Apps running on virtual machines have no awareness that they are sharing a physical computer. \nVirtualization also allows the users of the datacenter to spin up a new \"computer\" (aka a VM) in minutes \nwithout worrying about the physical constraints of adding a new computer to a datacenter. \nVMs also enable users to speed up the time to get a new virtual computer.",
    "slug": "virtualization"
  },
  {
    "url": "https://glossary.cncf.io/virtual-machine",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/virtual-machine.md",
    "title": "Virtual Machine",
    "status": "Completed",
    "category": "Technology",
    "tags": [
      "fundamental",
      "infrastructure"
    ],
    "markdown": "## What it is\n\nA virtual machine (VM) is a computer and its operating system \nthat is not bound to a particular piece of hardware. \nVMs rely on [virtualization](https://glossary.cncf.io/virtualization/) to carve a single physical computer into multiple virtual computers. \nThat separation allows organizations and infrastructure providers to \neasily create and destroy VMs without impacting the underlying hardware.\n\n## Problem it addresses\n\nVirtual machines take advantage of virtualization. \nWhen a [bare metal](https://glossary.cncf.io/bare-metal-machine/) machine is bound to a single operating system, \nhow well the machine's resources can be used is somewhat limited. \nAlso, when an operating system is bound to a single physical machine, \nits availability is directly tied to that hardware. \nIf the physical machine is offline due to maintenance or hardware failures, so is the operating system.\n\n## How it helps\n\nBy removing the direct relationship between an operating system and a single physical machine, \nyou solve several problems of bare metal machines: \nprovisioning time, hardware utilization, and resiliency.\n\nWith no new hardware to be bought, installed, or configured to support it, \nprovisioning time for a new computer is dramatically improved. \nVMs allow you to use your existing physical hardware resources better \nby placing multiple virtual machines on a single physical machine. \nNot bound to a particular physical machine, VMs are also more resilient than physical machines. \nWhen a physical machine needs to go offline, \nthe VMs running on it can be moved to another machine with little to no downtime\n",
    "what_it_is": "A virtual machine (VM) is a computer and its operating system \nthat is not bound to a particular piece of hardware. \nVMs rely on [virtualization](https://glossary.cncf.io/virtualization/) to carve a single physical computer into multiple virtual computers. \nThat separation allows organizations and infrastructure providers to \neasily create and destroy VMs without impacting the underlying hardware.",
    "problem_it_addresses": "Virtual machines take advantage of virtualization. \nWhen a [bare metal](https://glossary.cncf.io/bare-metal-machine/) machine is bound to a single operating system, \nhow well the machine's resources can be used is somewhat limited. \nAlso, when an operating system is bound to a single physical machine, \nits availability is directly tied to that hardware. \nIf the physical machine is offline due to maintenance or hardware failures, so is the operating system.",
    "how_it_helps": "By removing the direct relationship between an operating system and a single physical machine, \nyou solve several problems of bare metal machines: \nprovisioning time, hardware utilization, and resiliency.\n\nWith no new hardware to be bought, installed, or configured to support it, \nprovisioning time for a new computer is dramatically improved. \nVMs allow you to use your existing physical hardware resources better \nby placing multiple virtual machines on a single physical machine. \nNot bound to a particular physical machine, VMs are also more resilient than physical machines. \nWhen a physical machine needs to go offline, \nthe VMs running on it can be moved to another machine with little to no downtime",
    "slug": "virtual-machine"
  },
  {
    "url": "https://glossary.cncf.io/vertical-scaling",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/vertical-scaling.md",
    "title": "Vertical Scaling",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "infrastructure"
    ],
    "markdown": "## What it is\n\nVertical scaling, also known as \"scaling up and down\", is a technique where \na system's capacity is increased by adding CPU and memory to individual [nodes](https://glossary.cncf.io/nodes/) as the workload increases. \nLet's say, you have a computer of 4GB RAM and want to increase its capacity to 16GB RAM, \nscaling it vertically means switching to a 16GB RAM system. \n(Please refer to [horizontal scaling](https://glossary.cncf.io/horizontal-scaling/) for a different scaling approach.)\n\n## Problem it addresses\n\nAs demand for an application grows beyond the current capacity of that application instance, \nwe need to find a way to scale (add capacity to) the system. \nWe can either add more compute resources to existing nodes (vertical scaling) \nor more nodes to the system ([horizontal scaling](https://glossary.cncf.io/horizontal-scaling/)). \n[Scalability](https://glossary.cncf.io/scalability/) contributes to competitiveness, efficiency, reputation, and quality.\n\n## How it helps\n\nVertical scaling allows you to resize your server without changing the application code. \nThat contrasts to horizontal scaling, where the app must be replicable to scale, potentially requiring code updates. \nVertical scaling increases the capacity of an existing application by \nadding compute resources, allowing the app to process more requests and do more work concurrently.\n\n## Related terms\n\n* [Horizontal Scaling](https://glossary.cncf.io/horizontal-scaling/)\n* [Auto Scaling](https://glossary.cncf.io/auto-scaling/)\n",
    "what_it_is": "Vertical scaling, also known as \"scaling up and down\", is a technique where \na system's capacity is increased by adding CPU and memory to individual [nodes](https://glossary.cncf.io/nodes/) as the workload increases. \nLet's say, you have a computer of 4GB RAM and want to increase its capacity to 16GB RAM, \nscaling it vertically means switching to a 16GB RAM system. \n(Please refer to [horizontal scaling](https://glossary.cncf.io/horizontal-scaling/) for a different scaling approach.)",
    "problem_it_addresses": "As demand for an application grows beyond the current capacity of that application instance, \nwe need to find a way to scale (add capacity to) the system. \nWe can either add more compute resources to existing nodes (vertical scaling) \nor more nodes to the system ([horizontal scaling](https://glossary.cncf.io/horizontal-scaling/)). \n[Scalability](https://glossary.cncf.io/scalability/) contributes to competitiveness, efficiency, reputation, and quality.",
    "how_it_helps": "Vertical scaling allows you to resize your server without changing the application code. \nThat contrasts to horizontal scaling, where the app must be replicable to scale, potentially requiring code updates. \nVertical scaling increases the capacity of an existing application by \nadding compute resources, allowing the app to process more requests and do more work concurrently.",
    "related_terms": "* [Horizontal Scaling](https://glossary.cncf.io/horizontal-scaling/)\n* [Auto Scaling](https://glossary.cncf.io/auto-scaling/)",
    "slug": "vertical-scaling"
  },
  {
    "url": "https://glossary.cncf.io/version-control",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/version-control.md",
    "title": "Version Control",
    "status": "Deprecated",
    "category": "Technology",
    "draft": true,
    "tags": [
      "methodology"
    ],
    "markdown": "## What it is\n\nSource control (or version control) is the practice of tracking and managing changes to a document. \nIt is a system that records changes to a file or set of files over time so that you can recall specific versions later. \n\n## Problem it addresses\n\nVersion control systems work to address the following problems, \nbacking up a document or codebase as it changes over time, \nallowing multiple users to resolve conflicts when there are overlapping changes, and \nstoring a log of changes over time. \nApplication code can often be complex and critical to key business processes, \nso it is important to track who changed what, when it was changed, and why. \nAlso, many, if not most applications, are modified by multiple developers, \nand there are often conflicts between the changes introduced by different developers.\n\n## How it helps\n\nVersion control helps developers move fast and preserve efficiency \nwhile storing a record of changes and providing a facility to resolve conflicts. \nIt allows them to store application code in a repository and simplify collaboration. \nModern application development relies heavily on version control systems, like git, to store their code.\n",
    "what_it_is": "Source control (or version control) is the practice of tracking and managing changes to a document. \nIt is a system that records changes to a file or set of files over time so that you can recall specific versions later.",
    "problem_it_addresses": "Version control systems work to address the following problems, \nbacking up a document or codebase as it changes over time, \nallowing multiple users to resolve conflicts when there are overlapping changes, and \nstoring a log of changes over time. \nApplication code can often be complex and critical to key business processes, \nso it is important to track who changed what, when it was changed, and why. \nAlso, many, if not most applications, are modified by multiple developers, \nand there are often conflicts between the changes introduced by different developers.",
    "how_it_helps": "Version control helps developers move fast and preserve efficiency \nwhile storing a record of changes and providing a facility to resolve conflicts. \nIt allows them to store application code in a repository and simplify collaboration. \nModern application development relies heavily on version control systems, like git, to store their code.",
    "slug": "version-control"
  },
  {
    "url": "https://glossary.cncf.io/transport-layer-security",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/transport-layer-security.md",
    "title": "Transport Layer Security (TLS)",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "security",
      "networking"
    ],
    "markdown": "## What it is\r\n\r\nTransport Layer Security (TLS) is a protocol designed to provide increased security to communication over a network. \r\nIt ensures the secure delivery of data sent over the Internet, \r\navoiding possible monitoring and/or alteration of the data. \r\nThis protocol is widely used in applications such as messaging, e-mail, etc.\r\n\r\n## Problem it addresses \r\n\r\nWithout TLS, sensitive information such as browsing habits, e-mail correspondence, online chats, and conferencing calls can \r\neasily be traced and modified by others during the transmission. \r\nEnabling server and client applications to support TLS ensures that \r\ndata transmitted between them is encrypted and not viewable by third parties.\r\n\r\n## How it helps\r\n\r\nTLS uses a combination of encoding techniques that provide security while transmitting data over a network. \r\nTLS allows for an encrypted connection between a client application and a server, like a web browser and a banking site. \r\nIt also allows client applications to positively identify the server they are calling to, \r\nwhich reduces the risk of a client talking to a fraudulent site. \r\nThis ensures that third parties are unable to see and monitor data transmitted between applications using TLS, \r\nwhich protects sensitive and private information such as credit card numbers, passwords, location, etc.\r\n",
    "what_it_is": "Transport Layer Security (TLS) is a protocol designed to provide increased security to communication over a network. \r\nIt ensures the secure delivery of data sent over the Internet, \r\navoiding possible monitoring and/or alteration of the data. \r\nThis protocol is widely used in applications such as messaging, e-mail, etc.",
    "problem_it_addresses": "Without TLS, sensitive information such as browsing habits, e-mail correspondence, online chats, and conferencing calls can \r\neasily be traced and modified by others during the transmission. \r\nEnabling server and client applications to support TLS ensures that \r\ndata transmitted between them is encrypted and not viewable by third parties.",
    "how_it_helps": "TLS uses a combination of encoding techniques that provide security while transmitting data over a network. \r\nTLS allows for an encrypted connection between a client application and a server, like a web browser and a banking site. \r\nIt also allows client applications to positively identify the server they are calling to, \r\nwhich reduces the risk of a client talking to a fraudulent site. \r\nThis ensures that third parties are unable to see and monitor data transmitted between applications using TLS, \r\nwhich protects sensitive and private information such as credit card numbers, passwords, location, etc.",
    "slug": "transport-layer-security"
  },
  {
    "url": "https://glossary.cncf.io/tightly-coupled-architectures",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/tightly-coupled-architectures.md",
    "title": "Tightly Coupled Architectures",
    "status": "Completed",
    "category": "Property",
    "tags": [
      "fundamental",
      "architecture",
      "property"
    ],
    "markdown": "Tightly coupled architecture is an architectural style where a number of application components are interdependent \n(the opposite paradigm of [loosely coupled architectures](https://glossary.cncf.io/loosely-coupled-architecture/)). \nThis means that a change in one component will likely impact other components. \nIt is generally easier to implement than more loosely coupled architectural styles, \nbut can leave a system more vulnerable to cascading failures. \nThey also tend to require coordinated rollouts of components \nwhich can become a drag on developer productivity.\n\nTightly coupled application architectures are a fairly traditional way of building applications. \nWhile not necessarily consistent with all the best practices of [microservice](https://glossary.cncf.io/microservices/) development \nthey can be useful in specific circumstances. \nThey tend to be faster and simpler to implement and \nmuch like [monolithic applications](https://glossary.cncf.io/monolithic-apps/) they can speed up the initial development cycle.\n",
    "slug": "tightly-coupled-architectures"
  },
  {
    "url": "https://glossary.cncf.io/stateless-apps",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/stateless-apps.md",
    "title": "Stateless Apps",
    "status": "Feedback Appreciated",
    "category": "technology",
    "tags": [
      "fundamental",
      "application"
    ],
    "markdown": "## What it is\n\nA stateless application doesn’t save any client session (state) data on the server where the application lives. \nEach session is carried out as if it was the first time and responses are not dependent upon data from a previous session and \nprovides functionality to use print services, CDN (Content Delivery Network) or the Web Servers \nin order to process every short-term request. \nFor example, someone is searching a question in the search engine and pressed the Enter button. \nIn case if the searching operation gets interrupted or closed due to some reason, \nyou have to start a new one as there is no saved data for your previous request.\n\n## Problem it addresses\n\nStateless applications tackle the problem of resiliency, \nbecause different pods across a [cluster](https://glossary.cncf.io/cluster/) can work independently, \nwith multiple requests coming to them at the same time. \nIf there’s a problem, you can easily restart the application, \nand it will return to its initial state with little or no downtime. \nAs such, the benefits of stateless applications include resiliency, elasticity, and high availability. \nHowever, most applications we use today are at least partly [stateful](https://glossary.cncf.io/stateful-apps/), \nas they store things like preferences and settings to improve the user experience.\n\n## How it helps\n\nBoiling everything down, in a Stateless Application the only thing your cluster is responsible for is \nthe code, and other static content, being hosted on it. \nThat’s it, no changing databases, no writes and no left over files when the pod is deleted. \nStateless [containers](https://glossary.cncf.io/container/) are easier to deploy, \nand you don’t need to worry about saving container data on persistent storage volumes. \nYou also don't have to worry about backing up the data.\n",
    "what_it_is": "A stateless application doesn’t save any client session (state) data on the server where the application lives. \nEach session is carried out as if it was the first time and responses are not dependent upon data from a previous session and \nprovides functionality to use print services, CDN (Content Delivery Network) or the Web Servers \nin order to process every short-term request. \nFor example, someone is searching a question in the search engine and pressed the Enter button. \nIn case if the searching operation gets interrupted or closed due to some reason, \nyou have to start a new one as there is no saved data for your previous request.",
    "problem_it_addresses": "Stateless applications tackle the problem of resiliency, \nbecause different pods across a [cluster](https://glossary.cncf.io/cluster/) can work independently, \nwith multiple requests coming to them at the same time. \nIf there’s a problem, you can easily restart the application, \nand it will return to its initial state with little or no downtime. \nAs such, the benefits of stateless applications include resiliency, elasticity, and high availability. \nHowever, most applications we use today are at least partly [stateful](https://glossary.cncf.io/stateful-apps/), \nas they store things like preferences and settings to improve the user experience.",
    "how_it_helps": "Boiling everything down, in a Stateless Application the only thing your cluster is responsible for is \nthe code, and other static content, being hosted on it. \nThat’s it, no changing databases, no writes and no left over files when the pod is deleted. \nStateless [containers](https://glossary.cncf.io/container/) are easier to deploy, \nand you don’t need to worry about saving container data on persistent storage volumes. \nYou also don't have to worry about backing up the data.",
    "slug": "stateless-apps"
  },
  {
    "url": "https://glossary.cncf.io/stateful-apps",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/stateful-apps.md",
    "title": "Stateful Apps",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "fundamental",
      "application"
    ],
    "markdown": "## What it is\n\nWhen we speak of stateful (and [stateless](https://glossary.cncf.io/stateless-apps/)) apps, \nstate refers to any data the app needs to store to function as designed. \nAny kind of online shop that remembers your cart is a stateful app for example. \n\n## Problem it addresses\n\nUsing an app generally requires multiple requests. \nFor example, when online banking, you'll authenticate yourself by \nentering your password (request #1), \nthen you may transfer money to a friend (request #2), \nand finally, you'll want to view transfer details (request #3). \nTo function correctly, each step has to remember the previous ones, \nand the bank needs to remember the state of everyone’s accounts. \nToday, most applications we use are at least partly stateful, \nas they store things like preferences and settings to improve the user experience.\n\n## How it helps\n\nThere are several ways to store state for a stateful application. \nThe simplest is to hold the state in memory and not persist it anywhere. \nThe problem with that is, whenever the application has to be restarted, all state is lost. \nIn order to prevent that, state is persisted either locally (on disk) or in database systems. \n",
    "what_it_is": "When we speak of stateful (and [stateless](https://glossary.cncf.io/stateless-apps/)) apps, \nstate refers to any data the app needs to store to function as designed. \nAny kind of online shop that remembers your cart is a stateful app for example.",
    "problem_it_addresses": "Using an app generally requires multiple requests. \nFor example, when online banking, you'll authenticate yourself by \nentering your password (request #1), \nthen you may transfer money to a friend (request #2), \nand finally, you'll want to view transfer details (request #3). \nTo function correctly, each step has to remember the previous ones, \nand the bank needs to remember the state of everyone’s accounts. \nToday, most applications we use are at least partly stateful, \nas they store things like preferences and settings to improve the user experience.",
    "how_it_helps": "There are several ways to store state for a stateful application. \nThe simplest is to hold the state in memory and not persist it anywhere. \nThe problem with that is, whenever the application has to be restarted, all state is lost. \nIn order to prevent that, state is persisted either locally (on disk) or in database systems.",
    "slug": "stateful-apps"
  },
  {
    "url": "https://glossary.cncf.io/software-as-a-service",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/software-as-a-service.md",
    "title": "",
    "Title": "Software as a Service (SaaS)",
    "Status": "Deprecated",
    "Category": "Technology",
    "draft": true,
    "tags": [
      "fundamental",
      "platform"
    ],
    "markdown": "## What it is\n\nSoftware as a service (SaaS) allows users to connect to and use cloud-based services over the Internet. \nCommon examples are email, calendaring, and office tools (such as Gmail, Amazon Web Services, GitHub, Slack). \nSaaS provides complete software solutions on a pay-as-you-go basis. \nAll operations and maintenance tasks, and application data, are handled by the service provider.\n\n## Problem it addresses\n\nTraditionally, business software is installed on individual computers, requiring an admin to maintain and update. \nAs an example: An organization may use on-premise software for customer relationship management (CRM). \nThis software needs to be purchased, installed, secured, maintained, and regularly upgraded \nby the internal IT department, placing a burden on the IT team. \nThe up front cost associated with licenses, installation, and potentially additional hardware can be prohibitive. \nIt can also be difficult to respond to demand and [scale](https://glossary.cncf.io/scalability/) up and down \nas needed quickly in response to growth or change.\n\n## How it helps\n\nSaaS applications work without requiring any particular effort from your internal IT organization. \nThey are installed, maintained, upgraded, and secured by the vendor. \nIssues of scale, availability, and capacity are handled by the service provider, and, \nwith a pay-as-you-go model, they can be an affordable way for organizations to leverage enterprise applications.\n",
    "what_it_is": "Software as a service (SaaS) allows users to connect to and use cloud-based services over the Internet. \nCommon examples are email, calendaring, and office tools (such as Gmail, Amazon Web Services, GitHub, Slack). \nSaaS provides complete software solutions on a pay-as-you-go basis. \nAll operations and maintenance tasks, and application data, are handled by the service provider.",
    "problem_it_addresses": "Traditionally, business software is installed on individual computers, requiring an admin to maintain and update. \nAs an example: An organization may use on-premise software for customer relationship management (CRM). \nThis software needs to be purchased, installed, secured, maintained, and regularly upgraded \nby the internal IT department, placing a burden on the IT team. \nThe up front cost associated with licenses, installation, and potentially additional hardware can be prohibitive. \nIt can also be difficult to respond to demand and [scale](https://glossary.cncf.io/scalability/) up and down \nas needed quickly in response to growth or change.",
    "how_it_helps": "SaaS applications work without requiring any particular effort from your internal IT organization. \nThey are installed, maintained, upgraded, and secured by the vendor. \nIssues of scale, availability, and capacity are handled by the service provider, and, \nwith a pay-as-you-go model, they can be an affordable way for organizations to leverage enterprise applications.",
    "slug": "software-as-a-service"
  },
  {
    "url": "https://glossary.cncf.io/site-reliability-engineering",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/site-reliability-engineering.md",
    "title": "Site Reliability Engineering",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology"
    ],
    "markdown": "## What it is\n\nSite Reliability Engineering or SRE is a discipline that combines operations and software engineering. \nThe latter is applied to infrastructure and operations problems, specifically. \nMeaning, instead of building product features, Site Reliability Engineers build systems to run applications. \nThere are similarities with [DevOps](https://glossary.cncf.io/devops/), but while DevOps focuses on getting code to production, \nSRE ensures that code running in production works properly.\n\n## Problem it addresses\n\nEnsuring applications run [reliably](https://glossary.cncf.io/reliability/) requires multiple capabilities, \nfrom performance monitoring, alerting, [debugging](https://glossary.cncf.io/debugging/) to troubleshooting. \nWithout these, system operators can only react to problems vs. proactively working towards avoiding them \n— downtime only becomes a matter of time.\n\n## How it helps\n\nAn SRE approach minimizes the cost, time, and effort of the software development process \nby continuously improving the underlying system. \nThe system continuously measures and monitors the infrastructure and application components. \nWhen something goes wrong, the system points Site Reliability Engineers to when, where, and how to fix it. \nThis approach helps create highly [scalable](https://glossary.cncf.io/scalability/) and reliable software systems by automating operational tasks.\n",
    "what_it_is": "Site Reliability Engineering or SRE is a discipline that combines operations and software engineering. \nThe latter is applied to infrastructure and operations problems, specifically. \nMeaning, instead of building product features, Site Reliability Engineers build systems to run applications. \nThere are similarities with [DevOps](https://glossary.cncf.io/devops/), but while DevOps focuses on getting code to production, \nSRE ensures that code running in production works properly.",
    "problem_it_addresses": "Ensuring applications run [reliably](https://glossary.cncf.io/reliability/) requires multiple capabilities, \nfrom performance monitoring, alerting, [debugging](https://glossary.cncf.io/debugging/) to troubleshooting. \nWithout these, system operators can only react to problems vs. proactively working towards avoiding them \n— downtime only becomes a matter of time.",
    "how_it_helps": "An SRE approach minimizes the cost, time, and effort of the software development process \nby continuously improving the underlying system. \nThe system continuously measures and monitors the infrastructure and application components. \nWhen something goes wrong, the system points Site Reliability Engineers to when, where, and how to fix it. \nThis approach helps create highly [scalable](https://glossary.cncf.io/scalability/) and reliable software systems by automating operational tasks.",
    "slug": "site-reliability-engineering"
  },
  {
    "url": "https://glossary.cncf.io/shift-left",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/shift-left.md",
    "title": "Shift Left",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "methodology"
    ],
    "markdown": "## What it is\n\nLeft in Shift Left refers to earlier stages in a software development lifecycle, \nthinking of the lifecycle as a line where stages are executed from left to right. \nShift Left is the practice of implementing tests, security, or other development practices \nearly in the software development lifecycle rather than towards the end. \n\nAlthough originally used to refer to the process of testing early, \nShift Left can now also be applied to other aspects of software development and [DevOps](https://glossary.cncf.io/devops/), such as security and deployment. \n\n## Problem it addresses\n\nSecurity issues, bugs, and software defects can be more difficult and expensive to fix \nif they are discovered late in the development cycle or after deployment, \nparticularly if the software has already been deployed into production. \n\n## How it helps\n\nBy adopting a Shift Left mindset for software development, \nteams can implement testing and security throughout the development lifecycle. \nAnd because responsibility for testing and security is shared across the development team \n— from software engineers to quality assurance to operations — \neveryone plays a part in ensuring the stability and security of an application. \n\nIn addition, shifting left enables continuous improvement and \nfollows an [agile](https://glossary.cncf.io/agile-software-development/) rather than waterfall approach to development. \nTeams can make small iterative improvements and identify problems earlier on. \nThis approach allows engineers to adopt security and secure development practices \nas early as the design and architecture phase. \nTesting throughout the development cycle, decreases the time required for testing before a software release. \n\nMany software tools and SaaS solutions help shift these practices left. \nHowever, shift left can also be implemented through improved processes and cultural changes within a team.\n",
    "what_it_is": "Left in Shift Left refers to earlier stages in a software development lifecycle, \nthinking of the lifecycle as a line where stages are executed from left to right. \nShift Left is the practice of implementing tests, security, or other development practices \nearly in the software development lifecycle rather than towards the end. \n\nAlthough originally used to refer to the process of testing early, \nShift Left can now also be applied to other aspects of software development and [DevOps](https://glossary.cncf.io/devops/), such as security and deployment.",
    "problem_it_addresses": "Security issues, bugs, and software defects can be more difficult and expensive to fix \nif they are discovered late in the development cycle or after deployment, \nparticularly if the software has already been deployed into production.",
    "how_it_helps": "By adopting a Shift Left mindset for software development, \nteams can implement testing and security throughout the development lifecycle. \nAnd because responsibility for testing and security is shared across the development team \n— from software engineers to quality assurance to operations — \neveryone plays a part in ensuring the stability and security of an application. \n\nIn addition, shifting left enables continuous improvement and \nfollows an [agile](https://glossary.cncf.io/agile-software-development/) rather than waterfall approach to development. \nTeams can make small iterative improvements and identify problems earlier on. \nThis approach allows engineers to adopt security and secure development practices \nas early as the design and architecture phase. \nTesting throughout the development cycle, decreases the time required for testing before a software release. \n\nMany software tools and SaaS solutions help shift these practices left. \nHowever, shift left can also be implemented through improved processes and cultural changes within a team.",
    "slug": "shift-left"
  },
  {
    "url": "https://glossary.cncf.io/service",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/service.md",
    "title": "Service",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "application",
      "fundamental"
    ],
    "markdown": "Please note that in IT, service has multiple meanings. \nIn this definition, we'll focus on the more traditional one: service as in microservice. \nHow or even if services differ from microservices is nuanced and different people may have different opinions. \nFor a high-level definition, we'll treat them as the same. \nPlease refer to the [microservices](https://glossary.cncf.io/microservices/) definition.\n",
    "slug": "service"
  },
  {
    "url": "https://glossary.cncf.io/service-proxy",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/service-proxy.md",
    "title": "Service Proxy",
    "status": "Completed",
    "category": "technology",
    "tags": [
      "networking"
    ],
    "markdown": "## What it is\n\nA service proxy intercepts traffic to or from a given [service](https://glossary.cncf.io/service/), \napplies some logic to it, then forwards that traffic to another service. \nIt essentially acts as a “go-between” that collects information about network traffic and/or applies rules to it.\n\n## Problem it addresses\n\nTo keep track of service to service communication (aka network traffic) and \npotentially transform or redirect it, we need to collect data. \nTraditionally, the code enabling data collection and network traffic management was embedded within each application.\n\n## How it helps\n\nA service proxy allows us to “externalize” this functionality. \nNo longer does it need to live within the apps. \nInstead, it’s now embedded into the platform layer (where your apps run).\n\nActing as gatekeepers between services, proxies provide insight into what type of communication is happening. \nBased on their insight, they determine where to send a particular request or even deny it entirely.\n\nProxies gather critical data, manage routing (spreading traffic evenly among services or rerouting if some services break down), \nencrypt connections, and cache content (reducing resource consumption).\n",
    "what_it_is": "A service proxy intercepts traffic to or from a given [service](https://glossary.cncf.io/service/), \napplies some logic to it, then forwards that traffic to another service. \nIt essentially acts as a “go-between” that collects information about network traffic and/or applies rules to it.",
    "problem_it_addresses": "To keep track of service to service communication (aka network traffic) and \npotentially transform or redirect it, we need to collect data. \nTraditionally, the code enabling data collection and network traffic management was embedded within each application.",
    "how_it_helps": "A service proxy allows us to “externalize” this functionality. \nNo longer does it need to live within the apps. \nInstead, it’s now embedded into the platform layer (where your apps run).\n\nActing as gatekeepers between services, proxies provide insight into what type of communication is happening. \nBased on their insight, they determine where to send a particular request or even deny it entirely.\n\nProxies gather critical data, manage routing (spreading traffic evenly among services or rerouting if some services break down), \nencrypt connections, and cache content (reducing resource consumption).",
    "slug": "service-proxy"
  },
  {
    "url": "https://glossary.cncf.io/service-mesh",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/service-mesh.md",
    "title": "Service Mesh",
    "status": "Completed",
    "category": "technology",
    "tags": [
      "networking"
    ],
    "markdown": "## What it is\n\nIn a [microservices](https://glossary.cncf.io/microservices/) world, apps are broken down into multiple smaller [services](https://glossary.cncf.io/service/) that communicate over a network. \nJust like your wifi network, computer networks are intrinsically unreliable, hackable, and often slow. \nService meshes address this new set of challenges by managing traffic (i.e., communication) between services and \nadding [reliability](https://glossary.cncf.io/reliability/), [observability](https://glossary.cncf.io/observability/), and security features uniformly across all services.\n\n## Problem it addresses\n\nHaving moved to a microservices architecture, engineers are now dealing with hundreds, \npossibly even thousands of individual services, all needing to communicate. \nThat means a lot of traffic is going back and forth over the network. \nOn top of that, individual applications may need to encrypt communications to support regulatory requirements, \nprovide common metrics to operations teams, or provide detailed insight into traffic to help diagnose issues. \nIf built into the individual applications, \neach one of these features will cause friction between teams and slow down development of new features.\n\n## How it helps\n\nService meshes add reliability, observability, and security features \nuniformly across all services across a cluster without requiring code changes. \nBefore service meshes, that functionality had to be encoded into every single service, \nbecoming a potential source of bugs and technical debt.\n",
    "what_it_is": "In a [microservices](https://glossary.cncf.io/microservices/) world, apps are broken down into multiple smaller [services](https://glossary.cncf.io/service/) that communicate over a network. \nJust like your wifi network, computer networks are intrinsically unreliable, hackable, and often slow. \nService meshes address this new set of challenges by managing traffic (i.e., communication) between services and \nadding [reliability](https://glossary.cncf.io/reliability/), [observability](https://glossary.cncf.io/observability/), and security features uniformly across all services.",
    "problem_it_addresses": "Having moved to a microservices architecture, engineers are now dealing with hundreds, \npossibly even thousands of individual services, all needing to communicate. \nThat means a lot of traffic is going back and forth over the network. \nOn top of that, individual applications may need to encrypt communications to support regulatory requirements, \nprovide common metrics to operations teams, or provide detailed insight into traffic to help diagnose issues. \nIf built into the individual applications, \neach one of these features will cause friction between teams and slow down development of new features.",
    "how_it_helps": "Service meshes add reliability, observability, and security features \nuniformly across all services across a cluster without requiring code changes. \nBefore service meshes, that functionality had to be encoded into every single service, \nbecoming a potential source of bugs and technical debt.",
    "slug": "service-mesh"
  },
  {
    "url": "https://glossary.cncf.io/service-discovery",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/service-discovery.md",
    "title": "Service Discovery",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "networking"
    ],
    "markdown": "## What it is\n\nService discovery is the process of finding individual instances that make up a service. \nA service discovery tool keeps track of the various nodes or endpoints that make up a service. \n\n## Problem it addresses\n\nCloud native architectures are dynamic and fluid, meaning they are constantly changing. \nA [containerized](https://glossary.cncf.io/containerization/) app will likely end up starting and stopping multiple times in its lifetime. \nEach time that happens, it will have a new address and \nany app that wants to find it needs a tool to provide the new location information. \n\n## How it helps\n\nService discovery keeps track of apps within the network so they can find one another when needed. \nIt provides a common place to find and potentially identify individual services. \nService discovery engines are database-like tools that store info about what services exist and how to locate them.\n",
    "what_it_is": "Service discovery is the process of finding individual instances that make up a service. \nA service discovery tool keeps track of the various nodes or endpoints that make up a service.",
    "problem_it_addresses": "Cloud native architectures are dynamic and fluid, meaning they are constantly changing. \nA [containerized](https://glossary.cncf.io/containerization/) app will likely end up starting and stopping multiple times in its lifetime. \nEach time that happens, it will have a new address and \nany app that wants to find it needs a tool to provide the new location information.",
    "how_it_helps": "Service discovery keeps track of apps within the network so they can find one another when needed. \nIt provides a common place to find and potentially identify individual services. \nService discovery engines are database-like tools that store info about what services exist and how to locate them.",
    "slug": "service-discovery"
  },
  {
    "url": "https://glossary.cncf.io/serverless",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/serverless.md",
    "title": "",
    "Title": "Serverless",
    "Status": "Completed",
    "Category": "Technology",
    "tags": [
      "architecture"
    ],
    "markdown": "## What it is\n\nServerless is a cloud native development model that allows developers to \nbuild and run applications without having to manage servers. \nThere are still servers in serverless, but they are [abstracted](https://glossary.cncf.io/abstraction/) away from app development. \nA cloud provider handles the routine work of provisioning, maintaining, and [scaling](https://glossary.cncf.io/scalability/) the server infrastructure. \nDevelopers can simply package their code in [containers](https://glossary.cncf.io/container/) for deployment. \nOnce deployed, serverless apps respond to demand and automatically scale up and down as needed. \nServerless offerings from public cloud providers are usually metered on-demand through an event-driven execution model. \nAs a result, when a serverless function is sitting idle, it doesn’t cost anything.\n\n## Problem it addresses\n\nUnder a standard [Infrastructure-as-a-Service (IaaS)](https://glossary.cncf.io/infrastructure-as-a-service/) [cloud computing](https://glossary.cncf.io/cloud-computing/) model, \nusers pre-purchase units of capacity, meaning you pay a public cloud provider for always-on server components to run your apps. \nIt’s the user’s responsibility to scale up server capacity during times of high demand and \nto scale down when that capacity is no longer needed. \nThe cloud infrastructure necessary to run an app is active even when the app isn’t being used.\n\n## How it helps\n\nWith serverless architecture, by contrast, apps are launched only as needed. \nWhen an event triggers app code to run, the public cloud provider dynamically allocates resources for that code. \nThe user stops paying when the code finishes executing. \nIn addition to the cost and efficiency benefits, \nserverless frees developers from routine and menial tasks associated with app scaling and server provisioning. \nWith serverless, routine tasks such as managing the operating system and file system, security patches, \nload balancing, capacity management, scaling, logging, and monitoring are all offloaded to a cloud services provider.\n",
    "what_it_is": "Serverless is a cloud native development model that allows developers to \nbuild and run applications without having to manage servers. \nThere are still servers in serverless, but they are [abstracted](https://glossary.cncf.io/abstraction/) away from app development. \nA cloud provider handles the routine work of provisioning, maintaining, and [scaling](https://glossary.cncf.io/scalability/) the server infrastructure. \nDevelopers can simply package their code in [containers](https://glossary.cncf.io/container/) for deployment. \nOnce deployed, serverless apps respond to demand and automatically scale up and down as needed. \nServerless offerings from public cloud providers are usually metered on-demand through an event-driven execution model. \nAs a result, when a serverless function is sitting idle, it doesn’t cost anything.",
    "problem_it_addresses": "Under a standard [Infrastructure-as-a-Service (IaaS)](https://glossary.cncf.io/infrastructure-as-a-service/) [cloud computing](https://glossary.cncf.io/cloud-computing/) model, \nusers pre-purchase units of capacity, meaning you pay a public cloud provider for always-on server components to run your apps. \nIt’s the user’s responsibility to scale up server capacity during times of high demand and \nto scale down when that capacity is no longer needed. \nThe cloud infrastructure necessary to run an app is active even when the app isn’t being used.",
    "how_it_helps": "With serverless architecture, by contrast, apps are launched only as needed. \nWhen an event triggers app code to run, the public cloud provider dynamically allocates resources for that code. \nThe user stops paying when the code finishes executing. \nIn addition to the cost and efficiency benefits, \nserverless frees developers from routine and menial tasks associated with app scaling and server provisioning. \nWith serverless, routine tasks such as managing the operating system and file system, security patches, \nload balancing, capacity management, scaling, logging, and monitoring are all offloaded to a cloud services provider.",
    "slug": "serverless"
  },
  {
    "url": "https://glossary.cncf.io/self-healing",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/self-healing.md",
    "title": "Self Healing",
    "status": "Completed",
    "category": "property",
    "tags": [
      "infrastructure",
      "property"
    ],
    "markdown": "A self-healing system is capable of recovering from certain types of failure without any human intervention. \nIt has a \"convergence\" or \"control\" loop that actively looks at the system’s actual state and \ncompares it to the state that the operators initially desired. \nIf there is a difference (e.g., fewer application instances are running than desired), \nit will take corrective action (e.g., start new instances).\n",
    "slug": "self-healing"
  },
  {
    "url": "https://glossary.cncf.io/security-chaos-engineering",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/security-chaos-engineering.md",
    "title": "Security Chaos Engineering",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "security",
      "methodology"
    ],
    "markdown": "## What it is\n\nSecurity Chaos Engineering or SCE is a discipline based on [Chaos Engineering](https://glossary.cncf.io/chaos-engineering/). \nSCE performs proactive security experimentation on a distributed system \nto build confidence in the system's capability to withstand turbulent and malicious conditions. \nSecurity chaos engineers use scientific method loops to achieve this, \nincluding steady-state, hypothesis, continuous verification, lesson learned, and mitigation implementation.\n\n## Problem it addresses\n\nThe main priority for [site reliability engineers](https://glossary.cncf.io/site-reliability-engineering/) (SREs) and cyber security engineers is \nto restore service as fast as possible with the goal of achieving zero downtime and minimizing business impact. \nSREs and cyber security engineers deal both with pre-failure and post-failure incidents situations. \nMost security issues are challenging to discover and patch quickly, impacting application or system functionality. \nAdditionally, security incidents are usually tricky to uncover during the development phase.\n\n## How it helps\n\nSecurity Chaos Engineering is built around [observability](https://glossary.cncf.io/observability/) and cyber resiliency practices. \nIt aims to uncover the \"unknown unknowns\" and build confidence in the system, \nincreasing cyber resiliency and improving observability.\n\nEngineering teams will progressively improve the understanding for security concerns \nwithin complex infrastructure, platforms, and distributed systems. \nSCE improves the cyber resiliency of the entire product, uncovers hidden security issues, \nexposes the classical blind spots, and prepares teams for critical edge cases. \nThis approach helps SREs, [DevOps](https://glossary.cncf.io/devops/) and [DevSecOps](https://glossary.cncf.io/devsecops/) engineers \ncreate confidence in the system, increase cyber resiliency and improve observability.\n",
    "what_it_is": "Security Chaos Engineering or SCE is a discipline based on [Chaos Engineering](https://glossary.cncf.io/chaos-engineering/). \nSCE performs proactive security experimentation on a distributed system \nto build confidence in the system's capability to withstand turbulent and malicious conditions. \nSecurity chaos engineers use scientific method loops to achieve this, \nincluding steady-state, hypothesis, continuous verification, lesson learned, and mitigation implementation.",
    "problem_it_addresses": "The main priority for [site reliability engineers](https://glossary.cncf.io/site-reliability-engineering/) (SREs) and cyber security engineers is \nto restore service as fast as possible with the goal of achieving zero downtime and minimizing business impact. \nSREs and cyber security engineers deal both with pre-failure and post-failure incidents situations. \nMost security issues are challenging to discover and patch quickly, impacting application or system functionality. \nAdditionally, security incidents are usually tricky to uncover during the development phase.",
    "how_it_helps": "Security Chaos Engineering is built around [observability](https://glossary.cncf.io/observability/) and cyber resiliency practices. \nIt aims to uncover the \"unknown unknowns\" and build confidence in the system, \nincreasing cyber resiliency and improving observability.\n\nEngineering teams will progressively improve the understanding for security concerns \nwithin complex infrastructure, platforms, and distributed systems. \nSCE improves the cyber resiliency of the entire product, uncovers hidden security issues, \nexposes the classical blind spots, and prepares teams for critical edge cases. \nThis approach helps SREs, [DevOps](https://glossary.cncf.io/devops/) and [DevSecOps](https://glossary.cncf.io/devsecops/) engineers \ncreate confidence in the system, increase cyber resiliency and improve observability.",
    "slug": "security-chaos-engineering"
  },
  {
    "url": "https://glossary.cncf.io/search",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/search.md",
    "title": "Search Results",
    "layout": "search",
    "markdown": "",
    "slug": "search"
  },
  {
    "url": "https://glossary.cncf.io/scalability",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/scalability.md",
    "title": "Scalability",
    "status": "Completed",
    "category": "property",
    "tags": [
      "fundamental",
      "property"
    ],
    "markdown": "Scalability refers to how well a system can grow. \nThat is increasing the ability to do whatever the system is supposed to do. \nFor example, a [Kubernetes](https://glossary.cncf.io/kubernetes/) [cluster](https://glossary.cncf.io/cluster/) scales by \nincreasing or reducing the number of [containerized](https://glossary.cncf.io/containerization/) apps, \nbut that scalability depends on several factors. \nHow many [nodes](https://glossary.cncf.io/nodes/) does it have, how many [containers](https://glossary.cncf.io/container/) can each node handle, \nand how many records and operations can the control plane support?\n\nA scalable system makes it easy to add more capacity. \nWe differentiate between two scaling approaches. \nOn the one hand, there is [horizontal scaling](https://glossary.cncf.io/horizontal-scaling/) which adds more nodes to handle increased load. \nIn contrast, in [vertical scaling](https://glossary.cncf.io/vertical-scaling/) individual nodes are made more powerful to perform more transactions \n(e.g. by adding more memory or CPU to an individual machine). \nA scalable system is able to change easily and meet user needs.\n",
    "slug": "scalability"
  },
  {
    "url": "https://glossary.cncf.io/reliability",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/reliability.md",
    "title": "Reliability",
    "status": "Completed",
    "category": "property",
    "tags": [
      "fundamental",
      "property"
    ],
    "markdown": "From a cloud native perspective, reliability refers to how well a system responds to failures. \nIf we have a [distributed system](https://glossary.cncf.io/distributed-systems/) that keeps working as infrastructure changes and individual components fail, it is reliable. \nOn the other hand, if it fails easily and operators need to intervene manually to keep it running, it is unreliable. \nThe goal of [cloud native applications](https://glossary.cncf.io/cloud-native-apps/) is to build inherently reliable systems.\n",
    "slug": "reliability"
  },
  {
    "url": "https://glossary.cncf.io/portability",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/portability.md",
    "title": "Portability",
    "status": "Completed",
    "category": "Property",
    "tags": [
      "fundamental",
      "property"
    ],
    "markdown": "A software characteristic, portability is a form of reusability that helps to avoid \"lock-in\" to certain operating environments, \ne.g. cloud providers, operating systems or vendors. \n\nTraditionally, software is often built for specific environments (e.g. AWS or Linux). \nPortable software, on the other hand, works in different operating environments without needing major rework. \nAn application is considered portable if the effort required to adapt it to a new environment is within reasonable limits. \nThe phrase \"to port\" means to modify software and make it adaptable to work on a different computer system.\n",
    "slug": "portability"
  },
  {
    "url": "https://glossary.cncf.io/policy-as-code",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/policy-as-code.md",
    "title": "Policy as Code (PaC)",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology"
    ],
    "draft": null,
    "markdown": "## What it is\n\nPolicy as Code is the practice of storing the definition of policies as one or more files in machine-readable and processable form. \nThis replaces the traditional model where policies are documented in human-readable form in separate documents.\n\n## Problem it addresses\n\nBuilding applications and infrastructures are often constrained by many policies that an organization defines, \ne.g. security policies that forbid storing secrets in source code, running a container with superuser permissions, \nor storing some data outside a specific geo region.\nIt is very labor-intensive and error-prone for developers and reviewers to manually check applications and infrastructure against documented policies. \nManual processes cannot meet the responsiveness and scale requirements of cloud native applications.\n\n## How it helps\n\nDescribing policies through code enables repeatability and reduces errors (unlike when done manually). \nAnother advantage of Policy as Code is that code can be managed by a version control system like Git.\nGit creates a change log history which is particularly helpful when something does not work as expected.\nIt allows the user to determine who made the change and revert back to a previous version.  \n",
    "what_it_is": "Policy as Code is the practice of storing the definition of policies as one or more files in machine-readable and processable form. \nThis replaces the traditional model where policies are documented in human-readable form in separate documents.",
    "problem_it_addresses": "Building applications and infrastructures are often constrained by many policies that an organization defines, \ne.g. security policies that forbid storing secrets in source code, running a container with superuser permissions, \nor storing some data outside a specific geo region.\nIt is very labor-intensive and error-prone for developers and reviewers to manually check applications and infrastructure against documented policies. \nManual processes cannot meet the responsiveness and scale requirements of cloud native applications.",
    "how_it_helps": "Describing policies through code enables repeatability and reduces errors (unlike when done manually). \nAnother advantage of Policy as Code is that code can be managed by a version control system like Git.\nGit creates a change log history which is particularly helpful when something does not work as expected.\nIt allows the user to determine who made the change and revert back to a previous version.",
    "slug": "policy-as-code"
  },
  {
    "url": "https://glossary.cncf.io/platform-as-a-service",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/platform-as-a-service.md",
    "title": "Platform as a Service (PaaS)",
    "status": "Deprecated",
    "category": "Technology",
    "draft": true,
    "tags": [
      "fundamental",
      "platform"
    ],
    "markdown": "## What it is\n\nA Platform as a Service, or PaaS, is an external platform for application development teams to deploy and run their apps. \nHeroku, Cloud Foundry, App Engine are examples of PaaS offerings.\n\n## Problem it addresses\n\nTo take advantage of cloud native patterns like [microservices](https://glossary.cncf.io/microservices/) or [distributed applications](https://glossary.cncf.io/distributed-apps/), \noperations teams and developers need to be able to offload a significant amount of operations and maintenance work. \nThese include tasks like provisioning infrastructure, \nhandling [service discovery](https://glossary.cncf.io/service-discovery/) and load balancing, and [scaling](https://glossary.cncf.io/scalability/) applications.\n\n## How it helps\n\nA PaaS provides common infrastructure tools to application developers in a fully automated fashion. \nIt allows developers to understand and worry less about infrastructure and devote more time and effort to writing application code. \nIt also provides some monitoring and [observability](https://glossary.cncf.io/observability/) to help application teams ensure their apps are healthy.\n",
    "what_it_is": "A Platform as a Service, or PaaS, is an external platform for application development teams to deploy and run their apps. \nHeroku, Cloud Foundry, App Engine are examples of PaaS offerings.",
    "problem_it_addresses": "To take advantage of cloud native patterns like [microservices](https://glossary.cncf.io/microservices/) or [distributed applications](https://glossary.cncf.io/distributed-apps/), \noperations teams and developers need to be able to offload a significant amount of operations and maintenance work. \nThese include tasks like provisioning infrastructure, \nhandling [service discovery](https://glossary.cncf.io/service-discovery/) and load balancing, and [scaling](https://glossary.cncf.io/scalability/) applications.",
    "how_it_helps": "A PaaS provides common infrastructure tools to application developers in a fully automated fashion. \nIt allows developers to understand and worry less about infrastructure and devote more time and effort to writing application code. \nIt also provides some monitoring and [observability](https://glossary.cncf.io/observability/) to help application teams ensure their apps are healthy.",
    "slug": "platform-as-a-service"
  },
  {
    "url": "https://glossary.cncf.io/observability",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/observability.md",
    "title": "Observability",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "property"
    ],
    "markdown": "Observability is a system property that defines the degree to which the system can generate actionable insights. \nIt allows users to understand a system's state from these external outputs and take (corrective) action.\n\nComputer systems are measured by observing low-level signals such as CPU time, memory, disk space, and higher-level and business signals, including API response times, errors, transactions per second, etc.\nThese observable systems are **observed** (or monitored) through specialized tools, so-called observability tools. A list of these tools can be viewed in the [Cloud Native Landscape's observability section](https://landscape.cncf.io/card-mode?category=observability-and-analysis&grouping=category).\n\nObservable systems yield meaningful, actionable data to their operators, allowing them to achieve favorable outcomes (faster incident response, increased developer productivity) and less toil and downtime.\n\nConsequently, how observable a system is will significantly impact its operating and development costs. \n",
    "slug": "observability"
  },
  {
    "url": "https://glossary.cncf.io/nodes",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/nodes.md",
    "title": "Nodes",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "infrastructure",
      "fundamental"
    ],
    "markdown": "## What it is\n\nA node is a computer that works in concert with other computers, or nodes, to accomplish a common task. \nTake your laptop, modem, and printer, for example. \nThey are all connected over your wifi network communicating and collaborating, each representing one node. \nIn [cloud computing](https://glossary.cncf.io/cloud-computing/), a node can be a physical computer, \na virtual computer, referred to as a [VM](https://glossary.cncf.io/virtual-machine/), or even a [container](https://glossary.cncf.io/container/).\n\n## Problem it addresses\n\nWhile an application could (and many do) run on one single machine, there are some risks involved with that. \nNamely that the failure of the underlying system will disrupt the application. \nTo address this, developers started creating [distributed applications](https://glossary.cncf.io/distributed-apps/) where each process runs on its own node. \nThus, nodes run apps or processes as part of a group forming a [cluster](https://glossary.cncf.io/cluster/), or group, of nodes that works together to achieve a common goal.\n\n## How it helps\n\nA node gives you a distinct unit of compute (memory, CPU, network) that you can assign to a cluster. \nIn a [cloud native](https://glossary.cncf.io/cloud-native-tech/) platform or app a node represents a single unit that can perform work. \nIdeally, individual nodes are undifferentiated in that \nany one node of a particular type is indistinguishable from any other node of the same type.\n",
    "what_it_is": "A node is a computer that works in concert with other computers, or nodes, to accomplish a common task. \nTake your laptop, modem, and printer, for example. \nThey are all connected over your wifi network communicating and collaborating, each representing one node. \nIn [cloud computing](https://glossary.cncf.io/cloud-computing/), a node can be a physical computer, \na virtual computer, referred to as a [VM](https://glossary.cncf.io/virtual-machine/), or even a [container](https://glossary.cncf.io/container/).",
    "problem_it_addresses": "While an application could (and many do) run on one single machine, there are some risks involved with that. \nNamely that the failure of the underlying system will disrupt the application. \nTo address this, developers started creating [distributed applications](https://glossary.cncf.io/distributed-apps/) where each process runs on its own node. \nThus, nodes run apps or processes as part of a group forming a [cluster](https://glossary.cncf.io/cluster/), or group, of nodes that works together to achieve a common goal.",
    "how_it_helps": "A node gives you a distinct unit of compute (memory, CPU, network) that you can assign to a cluster. \nIn a [cloud native](https://glossary.cncf.io/cloud-native-tech/) platform or app a node represents a single unit that can perform work. \nIdeally, individual nodes are undifferentiated in that \nany one node of a particular type is indistinguishable from any other node of the same type.",
    "slug": "nodes"
  },
  {
    "url": "https://glossary.cncf.io/mutual-transport-layer-security",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/mutual-transport-layer-security.md",
    "title": "Mutual Transport Layer Security (mTLS)",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "security",
      "networking"
    ],
    "markdown": "## What it is\r\n\r\nMutual TLS (mTLS) is a technique used to authenticate and encrypt messages sent between two [services](https://glossary.cncf.io/service/). \r\nMutual TLS is the standard [Transport Layer Security](https://glossary.cncf.io/transport-layer-security/) (TLS) protocol but, \r\ninstead of validating the identity of just one connection, both sides are validated.\r\n\r\n## Problem it addresses\r\n\r\n[Microservices](https://glossary.cncf.io/microservices/) communicate over a network and, \r\njust like your wifi network, communication in transit over that network can be hacked. \r\nmTLS ensures that no unauthorized party can listen in on or impersonate legitimate requests.\r\n\r\n## How it helps\r\n\r\nmTLS ensures that traffic is secure and trusted in both directions between a client and server, \r\nproviding an additional layer of security for users who log in to a network or applications. \r\nIt also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices. \r\nAttacks like on-path attacks, spoofing attacks, credential stuffing, brute force attacks, etc. can be prevented by mTLS.\r\n",
    "what_it_is": "Mutual TLS (mTLS) is a technique used to authenticate and encrypt messages sent between two [services](https://glossary.cncf.io/service/). \r\nMutual TLS is the standard [Transport Layer Security](https://glossary.cncf.io/transport-layer-security/) (TLS) protocol but, \r\ninstead of validating the identity of just one connection, both sides are validated.",
    "problem_it_addresses": "[Microservices](https://glossary.cncf.io/microservices/) communicate over a network and, \r\njust like your wifi network, communication in transit over that network can be hacked. \r\nmTLS ensures that no unauthorized party can listen in on or impersonate legitimate requests.",
    "how_it_helps": "mTLS ensures that traffic is secure and trusted in both directions between a client and server, \r\nproviding an additional layer of security for users who log in to a network or applications. \r\nIt also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices. \r\nAttacks like on-path attacks, spoofing attacks, credential stuffing, brute force attacks, etc. can be prevented by mTLS.",
    "slug": "mutual-transport-layer-security"
  },
  {
    "url": "https://glossary.cncf.io/multitenancy",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/multitenancy.md",
    "title": "Multitenancy",
    "status": "Completed",
    "category": "Property",
    "tags": [
      "architecture",
      "property"
    ],
    "markdown": "## What it is\n\nMultitenancy (or multi-tenancy) refers to a single software installation that serves multiple tenants.\nA tenant is a user, application, or a group of users/applications that utilize the software to operate on their own data set.\nThese tenants don't share data (unless explicitly instructed by the owner) and may not even be aware of one another.\n\nA tenant can be as small as one independent user with a single login ID — think personal productivity\nsoftware — or as large as an entire corporation with thousands of login IDs, each with its own privileges\nyet interrelated in multiple ways. Multitenant software examples include Google Mail, Google Docs,\nMicrosoft Office 365, Salesforce CRM, and Dropbox, among many more that categorize as either entirely\nor partially multitenant software.\n\n## Problem it addresses\n\nWithout multitenancy, each tenant would need a dedicated software installation.\nThis increases resource utilization and maintenance efforts, ultimately software costs.\n\n## How it helps\n\nMultitenant software provides each tenant a segregated environment (work data, settings, list of credentials, etc.),\nsimultaneously serving multiple tenants. From a tenant's perspective, each has its dedicated software installation,\nalthough, in reality, they are all sharing one. This is achieved by running the software on a server and allowing\ntenants to connect to it over the network via an interface and/or an [API](https://glossary.cncf.io/application-programming-interface/)\n(also refer to [Client-Server Architecture](https://glossary.cncf.io/client-server-architecture/)).\nWith multitenant software, tenants share the resources of one installation without affecting each other or only\nin predefined and controlled ways. The resulting resource savings on the software provider's side can be passed\non to the tenants, significantly reducing the software cost for users (again, think web-based e-mail or document editors).\n\n## Related terms\n\nMultitenancy is not synonymous with [SaaS](https://glossary.cncf.io/software-as-a-service/),\nalthough it is very common for SaaS to be multitenant and even to feature multitenancy as one of its core benefits.\n",
    "what_it_is": "Multitenancy (or multi-tenancy) refers to a single software installation that serves multiple tenants.\nA tenant is a user, application, or a group of users/applications that utilize the software to operate on their own data set.\nThese tenants don't share data (unless explicitly instructed by the owner) and may not even be aware of one another.\n\nA tenant can be as small as one independent user with a single login ID — think personal productivity\nsoftware — or as large as an entire corporation with thousands of login IDs, each with its own privileges\nyet interrelated in multiple ways. Multitenant software examples include Google Mail, Google Docs,\nMicrosoft Office 365, Salesforce CRM, and Dropbox, among many more that categorize as either entirely\nor partially multitenant software.",
    "problem_it_addresses": "Without multitenancy, each tenant would need a dedicated software installation.\nThis increases resource utilization and maintenance efforts, ultimately software costs.",
    "how_it_helps": "Multitenant software provides each tenant a segregated environment (work data, settings, list of credentials, etc.),\nsimultaneously serving multiple tenants. From a tenant's perspective, each has its dedicated software installation,\nalthough, in reality, they are all sharing one. This is achieved by running the software on a server and allowing\ntenants to connect to it over the network via an interface and/or an [API](https://glossary.cncf.io/application-programming-interface/)\n(also refer to [Client-Server Architecture](https://glossary.cncf.io/client-server-architecture/)).\nWith multitenant software, tenants share the resources of one installation without affecting each other or only\nin predefined and controlled ways. The resulting resource savings on the software provider's side can be passed\non to the tenants, significantly reducing the software cost for users (again, think web-based e-mail or document editors).",
    "related_terms": "Multitenancy is not synonymous with [SaaS](https://glossary.cncf.io/software-as-a-service/),\nalthough it is very common for SaaS to be multitenant and even to feature multitenancy as one of its core benefits.",
    "slug": "multitenancy"
  },
  {
    "url": "https://glossary.cncf.io/monolithic-apps",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/monolithic-apps.md",
    "title": "Monolithic Apps",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "architecture",
      "fundamental"
    ],
    "markdown": "## What it is\n\nA monolithic application contains all functionality in a single deployable program. \nThis is often the simplest and easiest place to start when making an application. \nHowever, once the application grows in complexity, monoliths can become hard to maintain. \nWith more developers working on the same codebase, \nthe likelihood of conflicting changes and the need for interpersonal communication between developers increases.\n\n## Problem it Addresses\n\nDevolving an application into [microservices](https://glossary.cncf.io/microservices/) increases its operational overhead \n— there are more things to test, deploy, and keep running. \nEarly in a product’s lifecycle, it may be advantageous to defer this complexity and build a monolithic application \nuntil the product is determined successful.\n\n## How it Helps\n\nA well-designed monolith can uphold lean principles by being the simplest way to get an application up and running. \nWhen the business value of the monolithic application proves successful, it can be decomposed into microservices. \nCrafting a microservices-based app before it has proven valuable may be premature spending of engineering effort. \nIf the application yields no value, that effort becomes wasted.\n",
    "what_it_is": "A monolithic application contains all functionality in a single deployable program. \nThis is often the simplest and easiest place to start when making an application. \nHowever, once the application grows in complexity, monoliths can become hard to maintain. \nWith more developers working on the same codebase, \nthe likelihood of conflicting changes and the need for interpersonal communication between developers increases.",
    "problem_it_addresses": "Devolving an application into [microservices](https://glossary.cncf.io/microservices/) increases its operational overhead \n— there are more things to test, deploy, and keep running. \nEarly in a product’s lifecycle, it may be advantageous to defer this complexity and build a monolithic application \nuntil the product is determined successful.",
    "how_it_helps": "A well-designed monolith can uphold lean principles by being the simplest way to get an application up and running. \nWhen the business value of the monolithic application proves successful, it can be decomposed into microservices. \nCrafting a microservices-based app before it has proven valuable may be premature spending of engineering effort. \nIf the application yields no value, that effort becomes wasted.",
    "slug": "monolithic-apps"
  },
  {
    "url": "https://glossary.cncf.io/microservices-architecture",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/microservices-architecture.md",
    "title": "Microservices Architecture",
    "status": "Completed",
    "tags": [
      "architecture",
      "fundamental"
    ],
    "markdown": "## What it is\n\nA microservices architecture is an architectural approach that breaks applications into individual independent (micro)[services](https://glossary.cncf.io/service/), with each service focused on a specific functionality.\nThese services work together closely, appearing to the end user as a single entity. \nTake Netflix as an example. \nIts interface allows you to access, search, and preview videos. \nThese capabilities are likely powered by smaller services that each handle one functionality, e.g., authentication, search, and running previews in your browser.\n\nThis architectural approach allows developers to push out new features or update functionality much faster than if they were all tightly coupled, such as in a [monolithic application](https://glossary.cncf.io/monolithic-apps/) (more to that below).\n\n## Problem it addresses\n\nApplications are made up of different parts, each responsible for a specific capability. \nDemand for a particular functionality will not necessarily increase or decrease with demand for other app parts. \nGoing back to our Netflix example. \nLet's say that after a big marketing campaign, Netflix experiences a big spike in signups, but streaming has remained more or less stable in the early hours of the day.  \nThe surge in signups demands more signup capacity. \nTraditionally (monolithic approach), the entire app would have to be [scaled](https://glossary.cncf.io/scalability/) to accommodate the increase — a very inefficient use of resources. \n\nMonolithic architectures also make it easy for developers to succumb to design pitfalls. \nBecause all the code is in one place, it is easier to make that code [tightly coupled](https://glossary.cncf.io/tightly-coupled-architectures/) and harder to enforce the principle of separation of concerns. \nMonoliths also often require developers to understand the entire codebase before deploying any chances. \nMicroservices architecture is a response to these challenges.  \n\n\n## How it helps\n\nSeparating functionality into different microservices makes them easier to deploy, update, and scale independently. \nIt also allows different teams to work simultaneously on a small part of a bigger application without inadvertently negatively impacting the rest of the app. \nWhile a microservices architecture solves many problems, it also creates operational overhead — the things you need to deploy and keep track of increase by order of magnitude. \nMany [cloud-native technologies](https://glossary.cncf.io/cloud-native-tech/) aim to make microservices easier to deploy and manage.\n",
    "what_it_is": "A microservices architecture is an architectural approach that breaks applications into individual independent (micro)[services](https://glossary.cncf.io/service/), with each service focused on a specific functionality.\nThese services work together closely, appearing to the end user as a single entity. \nTake Netflix as an example. \nIts interface allows you to access, search, and preview videos. \nThese capabilities are likely powered by smaller services that each handle one functionality, e.g., authentication, search, and running previews in your browser.\n\nThis architectural approach allows developers to push out new features or update functionality much faster than if they were all tightly coupled, such as in a [monolithic application](https://glossary.cncf.io/monolithic-apps/) (more to that below).",
    "problem_it_addresses": "Applications are made up of different parts, each responsible for a specific capability. \nDemand for a particular functionality will not necessarily increase or decrease with demand for other app parts. \nGoing back to our Netflix example. \nLet's say that after a big marketing campaign, Netflix experiences a big spike in signups, but streaming has remained more or less stable in the early hours of the day.  \nThe surge in signups demands more signup capacity. \nTraditionally (monolithic approach), the entire app would have to be [scaled](https://glossary.cncf.io/scalability/) to accommodate the increase — a very inefficient use of resources. \n\nMonolithic architectures also make it easy for developers to succumb to design pitfalls. \nBecause all the code is in one place, it is easier to make that code [tightly coupled](https://glossary.cncf.io/tightly-coupled-architectures/) and harder to enforce the principle of separation of concerns. \nMonoliths also often require developers to understand the entire codebase before deploying any chances. \nMicroservices architecture is a response to these challenges.",
    "how_it_helps": "Separating functionality into different microservices makes them easier to deploy, update, and scale independently. \nIt also allows different teams to work simultaneously on a small part of a bigger application without inadvertently negatively impacting the rest of the app. \nWhile a microservices architecture solves many problems, it also creates operational overhead — the things you need to deploy and keep track of increase by order of magnitude. \nMany [cloud-native technologies](https://glossary.cncf.io/cloud-native-tech/) aim to make microservices easier to deploy and manage.",
    "slug": "microservices-architecture"
  },
  {
    "url": "https://glossary.cncf.io/managed-services",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/managed-services.md",
    "title": "Managed services",
    "status": "Deprecated",
    "draft": true,
    "category": "Technology",
    "tags": [],
    "markdown": "## What it is\n\nA managed service is a software offering where operations and management are taken care of by a third party. \nExamples include database as a service offerings like Amazon’s RDS or an external monitoring service like Datadog.\n\n## Problem it addresses\n\nManaging software is complex, especially considering all the different technologies that make up a modern stack. \nManaging each aspect of it and/or having in-house experts able to do so may be too expensive or not worth your engineers' time. \nYour team is likely better off building new capabilities than taking care of the operational tasks that can be easily outsourced.\n\n## How it helps\n\nManaged services are ready to use from day one with very little operational overhead. \nThey allow organizations to effectively outsource tasks that fall outside of their core competency \nwith well defined, and usually [API](https://glossary.cncf.io/application-programming-interface/) driven, boundaries.\n",
    "what_it_is": "A managed service is a software offering where operations and management are taken care of by a third party. \nExamples include database as a service offerings like Amazon’s RDS or an external monitoring service like Datadog.",
    "problem_it_addresses": "Managing software is complex, especially considering all the different technologies that make up a modern stack. \nManaging each aspect of it and/or having in-house experts able to do so may be too expensive or not worth your engineers' time. \nYour team is likely better off building new capabilities than taking care of the operational tasks that can be easily outsourced.",
    "how_it_helps": "Managed services are ready to use from day one with very little operational overhead. \nThey allow organizations to effectively outsource tasks that fall outside of their core competency \nwith well defined, and usually [API](https://glossary.cncf.io/application-programming-interface/) driven, boundaries.",
    "slug": "managed-services"
  },
  {
    "url": "https://glossary.cncf.io/loosely-coupled-architecture",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/loosely-coupled-architecture.md",
    "title": "Loosely Coupled Architecture",
    "status": "Completed",
    "category": "Property",
    "tags": [
      "fundamental",
      "architecture",
      "property"
    ],
    "markdown": "Loosely coupled architecture is an architectural style \nwhere the individual components of an application are built independently from one another \n(the opposite paradigm of [tightly coupled architectures](https://glossary.cncf.io/tightly-coupled-architectures/)). \nEach component, sometimes referred to as a [microservice](https://glossary.cncf.io/microservices/), is built to perform a specific function \nin a way that can be used by any number of other services. \nThis pattern is generally slower to implement than tightly coupled architecture \nbut has a number of benefits, particularly as applications scale.\n\nLoosely coupled applications allow teams to develop features, deploy, and scale independently, \nwhich allows organizations to iterate quickly on individual components. \nApplication development is faster and teams can be structured around their competency, \nfocusing on their specific application. \n",
    "slug": "loosely-coupled-architecture"
  },
  {
    "url": "https://glossary.cncf.io/load-balancer",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/load-balancer.md",
    "title": "Load Balancer",
    "status": "Feedback Appreciated",
    "category": "concept",
    "tags": [
      "infrastructure",
      "networking"
    ],
    "markdown": "## What it is\n\nA load balancer is a tool that efficiently distributes incoming requests among multiple instances of an application. \nTake a [microservice](https://glossary.cncf.io/microservices/) architecture for example, where each service can be [scaled horizontally](https://glossary.cncf.io/horizontal-scaling/). \nA load balancer sits in front of a scaled microservice and ensures that no one instance gets the bulk of the requests.\nLoad balancers can be software or hardware-based.\n\n## Problem it addresses\n\nModern applications and websites generally serve hundreds of thousands of simultaneous end-user requests. \nTo handle all those requests, applications are often scaled horizontally.\nBut horizontal scaling introduces a new challenge. How do you distribute incoming traffic to all services equally? \nThis is where load balancers come in.\n\n## How it helps\n\nLoad balancers dynamically distribute all incoming requests among multiple services, ensuring that no one service gets the bulk of it while others only get a few or none. \nIn short, it spreads the load across multiple services, following a defined schema (i.e., evenly or percentage-based). \nLoad balancers are essential to an application's overall performance and, ultimately, the user experience.\n",
    "what_it_is": "A load balancer is a tool that efficiently distributes incoming requests among multiple instances of an application. \nTake a [microservice](https://glossary.cncf.io/microservices/) architecture for example, where each service can be [scaled horizontally](https://glossary.cncf.io/horizontal-scaling/). \nA load balancer sits in front of a scaled microservice and ensures that no one instance gets the bulk of the requests.\nLoad balancers can be software or hardware-based.",
    "problem_it_addresses": "Modern applications and websites generally serve hundreds of thousands of simultaneous end-user requests. \nTo handle all those requests, applications are often scaled horizontally.\nBut horizontal scaling introduces a new challenge. How do you distribute incoming traffic to all services equally? \nThis is where load balancers come in.",
    "how_it_helps": "Load balancers dynamically distribute all incoming requests among multiple services, ensuring that no one service gets the bulk of it while others only get a few or none. \nIn short, it spreads the load across multiple services, following a defined schema (i.e., evenly or percentage-based). \nLoad balancers are essential to an application's overall performance and, ultimately, the user experience.",
    "slug": "load-balancer"
  },
  {
    "url": "https://glossary.cncf.io/kubernetes",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/kubernetes.md",
    "title": "Kubernetes",
    "status": "Completed",
    "category": "technology",
    "tags": [
      "infrastructure",
      "fundamental"
    ],
    "markdown": "## What it is\n\nKubernetes, often abbreviated as K8s, is an open source container orchestrator. \nIt automates the lifecycle of containerized applications on modern infrastructures, functioning as a \"datacenter operating system\" that manages applications across a [distributed system](https://glossary.cncf.io/distributed-systems/).\n\nKubernetes schedules [containers](https://glossary.cncf.io/container/) across [nodes](https://glossary.cncf.io/nodes/) in a [cluster](https://glossary.cncf.io/cluster/), bundling several infrastructure resources such as load balancer, persistent storage, etc. to run containerized applications.\n\nKubernetes enables automation and extensibility, allowing users to deploy applications declaratively (see below) in a reproducible way. \nKubernetes is extensible via its [API](https://glossary.cncf.io/application-programming-interface/), allowing experienced Kubernetes practitioners to leverage its automation capabilities according to their needs.\n\n## Problem it addresses\n\nInfrastructure automation and declarative configuration management have been important concepts for a long time, but they have become more pressing as [cloud computing](https://glossary.cncf.io/cloud-computing/) has gained popularity. \nAs demand for compute resources increases and organizations need to provide more operational capabilities with fewer engineers, new technologies and working methods are required to meet that demand. \n\n## How it helps\n\nSimilar to traditional [infrastructure as code](https://glossary.cncf.io/infrastructure-as-code/) tools, Kubernetes helps with automation but has the advantage of working with containers. \nContainers are more resistant to configuration drift than [virtual](https://glossary.cncf.io/virtual-machine/) or physical machines. \n\nAdditionally, Kubernetes works declaratively, which means that instead of operators instructing the machine how to do something, they describe — usually as manifest files (e.g., YAML) — what the infrastructure should look like. \nKubernetes then takes care of the \"how\". \nThis results in Kubernetes being extremely compatible with infrastructure as code.\n\nKubernetes also [self-heals](https://glossary.cncf.io/self-healing/). \nThe cluster's actual state will always match the operator's desired state.\nIf Kubernetes detects a deviation from what is described in the manifest files, a Kubernetes controller kicks in and fixes it. \nWhile the infrastructure Kubernetes uses may be continually changing, Kubernetes constantly and automatically adapts to changes and ensures that it matches with the desired state.\n",
    "what_it_is": "Kubernetes, often abbreviated as K8s, is an open source container orchestrator. \nIt automates the lifecycle of containerized applications on modern infrastructures, functioning as a \"datacenter operating system\" that manages applications across a [distributed system](https://glossary.cncf.io/distributed-systems/).\n\nKubernetes schedules [containers](https://glossary.cncf.io/container/) across [nodes](https://glossary.cncf.io/nodes/) in a [cluster](https://glossary.cncf.io/cluster/), bundling several infrastructure resources such as load balancer, persistent storage, etc. to run containerized applications.\n\nKubernetes enables automation and extensibility, allowing users to deploy applications declaratively (see below) in a reproducible way. \nKubernetes is extensible via its [API](https://glossary.cncf.io/application-programming-interface/), allowing experienced Kubernetes practitioners to leverage its automation capabilities according to their needs.",
    "problem_it_addresses": "Infrastructure automation and declarative configuration management have been important concepts for a long time, but they have become more pressing as [cloud computing](https://glossary.cncf.io/cloud-computing/) has gained popularity. \nAs demand for compute resources increases and organizations need to provide more operational capabilities with fewer engineers, new technologies and working methods are required to meet that demand.",
    "how_it_helps": "Similar to traditional [infrastructure as code](https://glossary.cncf.io/infrastructure-as-code/) tools, Kubernetes helps with automation but has the advantage of working with containers. \nContainers are more resistant to configuration drift than [virtual](https://glossary.cncf.io/virtual-machine/) or physical machines. \n\nAdditionally, Kubernetes works declaratively, which means that instead of operators instructing the machine how to do something, they describe — usually as manifest files (e.g., YAML) — what the infrastructure should look like. \nKubernetes then takes care of the \"how\". \nThis results in Kubernetes being extremely compatible with infrastructure as code.\n\nKubernetes also [self-heals](https://glossary.cncf.io/self-healing/). \nThe cluster's actual state will always match the operator's desired state.\nIf Kubernetes detects a deviation from what is described in the manifest files, a Kubernetes controller kicks in and fixes it. \nWhile the infrastructure Kubernetes uses may be continually changing, Kubernetes constantly and automatically adapts to changes and ensures that it matches with the desired state.",
    "slug": "kubernetes"
  },
  {
    "url": "https://glossary.cncf.io/infrastructure-as-code",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/infrastructure-as-code.md",
    "title": "Infrastructure as Code (IaC)",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "infrastructure",
      "methodology"
    ],
    "markdown": "## What it is\n\nInfrastructure as code is the practice of storing the definition of infrastructure as one or more files. \nThis replaces the traditional model where infrastructure as a service is provisioned manually, \nusually through shell scripts or other configuration tools.\n\n## Problem it addresses\n\nBuilding applications in a cloud native way requires infrastructure to be disposable and reproducible. \nIt also needs to [scale](https://glossary.cncf.io/scalability/) on-demand in an automated and repeatable way, potentially without human intervention. \nManual provisioning cannot meet the responsiveness and scale requirements of [cloud native applications](https://glossary.cncf.io/cloud-native-apps/). \nManual infrastructure changes are not reproducible, quickly run into scale limits, and introduces misconfiguration errors.\n\n## How it helps\n\nBy representing the data center resources such as servers, load balancers, and subnets as code, \nit allows infrastructure teams to have a single source of truth for all configurations and \nalso allows them to manage their data center in a [CI](https://glossary.cncf.io/continuous-integration/)/[CD](https://glossary.cncf.io/continuous-delivery/) pipeline, \nimplementing version control and deployment strategies.\n",
    "what_it_is": "Infrastructure as code is the practice of storing the definition of infrastructure as one or more files. \nThis replaces the traditional model where infrastructure as a service is provisioned manually, \nusually through shell scripts or other configuration tools.",
    "problem_it_addresses": "Building applications in a cloud native way requires infrastructure to be disposable and reproducible. \nIt also needs to [scale](https://glossary.cncf.io/scalability/) on-demand in an automated and repeatable way, potentially without human intervention. \nManual provisioning cannot meet the responsiveness and scale requirements of [cloud native applications](https://glossary.cncf.io/cloud-native-apps/). \nManual infrastructure changes are not reproducible, quickly run into scale limits, and introduces misconfiguration errors.",
    "how_it_helps": "By representing the data center resources such as servers, load balancers, and subnets as code, \nit allows infrastructure teams to have a single source of truth for all configurations and \nalso allows them to manage their data center in a [CI](https://glossary.cncf.io/continuous-integration/)/[CD](https://glossary.cncf.io/continuous-delivery/) pipeline, \nimplementing version control and deployment strategies.",
    "slug": "infrastructure-as-code"
  },
  {
    "url": "https://glossary.cncf.io/infrastructure-as-a-service",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/infrastructure-as-a-service.md",
    "title": "Infrastructure as a Service (IaaS)",
    "status": "Completed",
    "category": "Technology",
    "tags": [
      "infrastructure"
    ],
    "markdown": "## What it is\n\nInfrastructure as a service, or IaaS, is a [cloud computing](https://glossary.cncf.io/cloud-computing/) service model that \noffers [physical](https://glossary.cncf.io/bare-metal-machine/) or [virtualized](https://glossary.cncf.io/virtualization/) \ncompute, storage, and network resources on-demand on a pay-as-you-go model. \nCloud providers own and operate the hardware and software, \navailable to consumers in public, private, or hybrid cloud deployments.\n\n## Problem it addresses\n\nIn traditional on-premise setups, organizations often struggle with effective computing resource usage. \nData centers have to be built for potential peak demand, even if it's only needed 1% of the time. \nDuring lower demand, these compute resources are idle. \nAnd, if the workload spikes beyond the expected demand, \nthere is a shortage of computing resources to process the workload. \nThis lack of scalability leads to increased costs and ineffective resource usage.\n\n## How it helps\n\nWith IaaS organizations can avoid purchasing and maintaining compute and data center space for their applications. \nAn on-demand infrastructure allows them to rent compute resources as needed and \ndefer large capital expenditures, or [CAPEX](https://en.wikipedia.org/wiki/Capital_expenditure), \nwhile giving them the flexibility to scale up or down.\n\nIaaS reduces the upfront costs of experimenting or trying a new application and \nprovides facilities to rapidly deploy infrastructure. \nA cloud provider is an excellent option for development or test environments, \nwhich helps developers experiment and innovate.\n",
    "what_it_is": "Infrastructure as a service, or IaaS, is a [cloud computing](https://glossary.cncf.io/cloud-computing/) service model that \noffers [physical](https://glossary.cncf.io/bare-metal-machine/) or [virtualized](https://glossary.cncf.io/virtualization/) \ncompute, storage, and network resources on-demand on a pay-as-you-go model. \nCloud providers own and operate the hardware and software, \navailable to consumers in public, private, or hybrid cloud deployments.",
    "problem_it_addresses": "In traditional on-premise setups, organizations often struggle with effective computing resource usage. \nData centers have to be built for potential peak demand, even if it's only needed 1% of the time. \nDuring lower demand, these compute resources are idle. \nAnd, if the workload spikes beyond the expected demand, \nthere is a shortage of computing resources to process the workload. \nThis lack of scalability leads to increased costs and ineffective resource usage.",
    "how_it_helps": "With IaaS organizations can avoid purchasing and maintaining compute and data center space for their applications. \nAn on-demand infrastructure allows them to rent compute resources as needed and \ndefer large capital expenditures, or [CAPEX](https://en.wikipedia.org/wiki/Capital_expenditure), \nwhile giving them the flexibility to scale up or down.\n\nIaaS reduces the upfront costs of experimenting or trying a new application and \nprovides facilities to rapidly deploy infrastructure. \nA cloud provider is an excellent option for development or test environments, \nwhich helps developers experiment and innovate.",
    "slug": "infrastructure-as-a-service"
  },
  {
    "url": "https://glossary.cncf.io/immutable-infrastructure",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/immutable-infrastructure.md",
    "title": "Immutable Infrastructure",
    "status": "Completed",
    "category": "property",
    "tags": [
      "infrastructure",
      "property"
    ],
    "markdown": "Immutable Infrastructure refers to computer infrastructure \n([virtual machines](https://glossary.cncf.io/virtual-machine/), [containers](https://glossary.cncf.io/container/), network appliances) \nthat cannot be changed once deployed. \nThis can be enforced by an automated process that overwrites unauthorized changes or \nthrough a system that won't allow changes in the first place. \nContainers are a good example of immutable infrastructure \nbecause persistent changes to containers can only be made by \ncreating a new version of the container or recreating the existing container from its image.\n\nBy preventing or identifying unauthorized changes, \nimmutable infrastructures make it easier to identify and mitigate security risks. \nOperating such a system becomes a lot more straightforward \nbecause administrators can make assumptions about it. \nAfter all, they know no one made mistakes or changes they forgot to communicate. \nImmutable infrastructure goes hand-in-hand with [infrastructure as code](https://glossary.cncf.io/infrastructure-as-code/) \nwhere all automation needed to create infrastructure is stored in version control (e.g. Git). \nThis combination of immutability and version control means that \nthere is a durable audit log of every authorized change to a system.\n",
    "slug": "immutable-infrastructure"
  },
  {
    "url": "https://glossary.cncf.io/idempotence",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/idempotence.md",
    "title": "Idempotence",
    "status": "Completed",
    "category": "Property",
    "tags": [
      "property"
    ],
    "markdown": "In maths or computer science, idempotence describes an operation that always leads to the same outcome, \nno matter how many times you execute it. \nIf the parameters are the same, an idempotent operation won't affect the application it calls.\n",
    "slug": "idempotence"
  },
  {
    "url": "https://glossary.cncf.io/hypervisor",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/hypervisor.md",
    "title": "Hypervisor",
    "status": "Feedback Appreciated",
    "category": "Technology",
    "tags": [
      "application"
    ],
    "markdown": "## What it is\n\nA hypervisor enables [virtualization](https://glossary.cncf.io/virtualization/)\nby taking the advantage of [bare metal machine](https://glossary.cncf.io/bare-metal-machine/) resources\n(CPU, Memory, Network, and Storage), dividing them into sub-parts, \nand allocating resources accordingly to create  [virtual machines (VM)](https://glossary.cncf.io/virtual-machine/)\nuntil the underlying host reaches its performance limits.\n\n## Problem it addresses\n\nTraditionally, a server could only run applications of a single operating system.\nThe process of acquiring software takes time. It requires infrastructure with a specific environment\nand a team of engineers to manage and monitor them.\nServers were underutilized, considering the computing power of a server it can run multiple operating systems and more applications.\nRunning applications on bare metal wasn't enough to match the needs of fluctuating traffic.\n\n## How it helps\n\nIn the context of [cloud computing](https://glossary.cncf.io/cloud-computing/), the hypervisor becomes an effective tool.\nIn contrast to the traditional method of creating a virtual machine, a hypervisor makes the process much simpler and faster. \nHardware resources are logically partitioned and assigned to the VMs keeping them isolated as distinct units,\nensuring they function independently so that issues on one don't affect the others,\nand allowing VMs to install any necessary operating system.\nA hypervisor is an abstraction over the physical hardware, it takes care of those low-level complexities of managing the VMs and monitoring them,\nmaking VMs loosely bound to hardware, enabling organizations to migrate their applications to the remote servers/cloud \nand autoscale their services.\nOver time, the use of this [multi-tenant](https://glossary.cncf.io/multitenancy/) software has reduced computing costs.\n",
    "what_it_is": "A hypervisor enables [virtualization](https://glossary.cncf.io/virtualization/)\nby taking the advantage of [bare metal machine](https://glossary.cncf.io/bare-metal-machine/) resources\n(CPU, Memory, Network, and Storage), dividing them into sub-parts, \nand allocating resources accordingly to create  [virtual machines (VM)](https://glossary.cncf.io/virtual-machine/)\nuntil the underlying host reaches its performance limits.",
    "problem_it_addresses": "Traditionally, a server could only run applications of a single operating system.\nThe process of acquiring software takes time. It requires infrastructure with a specific environment\nand a team of engineers to manage and monitor them.\nServers were underutilized, considering the computing power of a server it can run multiple operating systems and more applications.\nRunning applications on bare metal wasn't enough to match the needs of fluctuating traffic.",
    "how_it_helps": "In the context of [cloud computing](https://glossary.cncf.io/cloud-computing/), the hypervisor becomes an effective tool.\nIn contrast to the traditional method of creating a virtual machine, a hypervisor makes the process much simpler and faster. \nHardware resources are logically partitioned and assigned to the VMs keeping them isolated as distinct units,\nensuring they function independently so that issues on one don't affect the others,\nand allowing VMs to install any necessary operating system.\nA hypervisor is an abstraction over the physical hardware, it takes care of those low-level complexities of managing the VMs and monitoring them,\nmaking VMs loosely bound to hardware, enabling organizations to migrate their applications to the remote servers/cloud \nand autoscale their services.\nOver time, the use of this [multi-tenant](https://glossary.cncf.io/multitenancy/) software has reduced computing costs.",
    "slug": "hypervisor"
  },
  {
    "url": "https://glossary.cncf.io/horizontal-scaling",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/horizontal-scaling.md",
    "title": "Horizontal Scaling",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "infrastructure"
    ],
    "markdown": "## What it is\n\nHorizontal scaling is a technique where a system's capacity is increased by adding more [nodes](https://glossary.cncf.io/nodes/) \nversus adding more compute resources to individual nodes (the latter being known as [vertical scaling](https://glossary.cncf.io/vertical-scaling/)). \nLet's say, we have a system of 4GB RAM and want to increase its capacity to 16GB RAM, \nscaling it horizontally means doing so by adding 4 x 4GB RAM rather than switching to a 16GB RAM system.\n\nThis approach enhances the performance of an application by adding new instances, or [nodes](https://glossary.cncf.io/nodes/), \nto better distribute the workload. \nIn simple words, it aims to decrease the server's load \nrather than expanding capacity of the individual server.\n\n## Problem it addresses\n\nAs demand for an application grows beyond the current capacity of that application instance, \nwe need to find a way to [scale](https://glossary.cncf.io/scalability/) (add capacity to) the system. \nWe can either add more nodes to the system (horizontal scaling) \nor more compute resources to existing nodes (vertical scaling).\n\n## How it helps\n\nHorizontal scaling allows applications to scale to whatever limits the underlying cluster provides. \nBy adding more instances to the system, the app can process a greater number of requests. \nIf a single node can handle 1,000 requests per second, \neach additional node should increase the total number of requests by around 1,000 requests per second. \nThis allows the application to do more work concurrently \nwithout needing to increase the capacity of any node in particular.\n\n## Related terms\n\n* [Vertical Scaling](https://glossary.cncf.io/vertical-scaling/)\n* [Auto Scaling](https://glossary.cncf.io/auto-scaling/)\n",
    "what_it_is": "Horizontal scaling is a technique where a system's capacity is increased by adding more [nodes](https://glossary.cncf.io/nodes/) \nversus adding more compute resources to individual nodes (the latter being known as [vertical scaling](https://glossary.cncf.io/vertical-scaling/)). \nLet's say, we have a system of 4GB RAM and want to increase its capacity to 16GB RAM, \nscaling it horizontally means doing so by adding 4 x 4GB RAM rather than switching to a 16GB RAM system.\n\nThis approach enhances the performance of an application by adding new instances, or [nodes](https://glossary.cncf.io/nodes/), \nto better distribute the workload. \nIn simple words, it aims to decrease the server's load \nrather than expanding capacity of the individual server.",
    "problem_it_addresses": "As demand for an application grows beyond the current capacity of that application instance, \nwe need to find a way to [scale](https://glossary.cncf.io/scalability/) (add capacity to) the system. \nWe can either add more nodes to the system (horizontal scaling) \nor more compute resources to existing nodes (vertical scaling).",
    "how_it_helps": "Horizontal scaling allows applications to scale to whatever limits the underlying cluster provides. \nBy adding more instances to the system, the app can process a greater number of requests. \nIf a single node can handle 1,000 requests per second, \neach additional node should increase the total number of requests by around 1,000 requests per second. \nThis allows the application to do more work concurrently \nwithout needing to increase the capacity of any node in particular.",
    "related_terms": "* [Vertical Scaling](https://glossary.cncf.io/vertical-scaling/)\n* [Auto Scaling](https://glossary.cncf.io/auto-scaling/)",
    "slug": "horizontal-scaling"
  },
  {
    "url": "https://glossary.cncf.io/gitops",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/gitops.md",
    "title": "GitOps",
    "status": "Feedback Appreciated",
    "category": "Concept",
    "tags": [
      "methodology"
    ],
    "markdown": "## What it is\n\nGitOps is a set of best practices based on [shared principles](https://opengitops.dev/), \napplied to a workflow that depends on software agents that \nenable automation to reconcile a declared system state or configuration in a git repository.\nThese software agents and practices are used to execute a cohesive workflow that \nleverages a source control system like Git as the “single source of truth” and \nextends this practice to applications, infrastructure, and operational procedures.\n\n## Problem it addresses\n\nExisting processes for infrastructure configuration management can face challenges \nsuch as configuration drift, failed deployments, relying on a system's previous state for success, \nmissing documentation, or unknown development history.\nAdopting a GitOps workflow can help alleviate these issues, among several others.\n\n## How it helps\n\nGitOps is a paradigm that can be applied to a workflow \nto help manage an application and cloud system infrastructure. \nIt enables organizations several advantages \nsuch as better coordination, transparency, stability, and reliability of a system.\nOperating in a close loop ensures the current live state of a system matches \nagainst the desired target state, specified in the git repository.\n",
    "what_it_is": "GitOps is a set of best practices based on [shared principles](https://opengitops.dev/), \napplied to a workflow that depends on software agents that \nenable automation to reconcile a declared system state or configuration in a git repository.\nThese software agents and practices are used to execute a cohesive workflow that \nleverages a source control system like Git as the “single source of truth” and \nextends this practice to applications, infrastructure, and operational procedures.",
    "problem_it_addresses": "Existing processes for infrastructure configuration management can face challenges \nsuch as configuration drift, failed deployments, relying on a system's previous state for success, \nmissing documentation, or unknown development history.\nAdopting a GitOps workflow can help alleviate these issues, among several others.",
    "how_it_helps": "GitOps is a paradigm that can be applied to a workflow \nto help manage an application and cloud system infrastructure. \nIt enables organizations several advantages \nsuch as better coordination, transparency, stability, and reliability of a system.\nOperating in a close loop ensures the current live state of a system matches \nagainst the desired target state, specified in the git repository.",
    "slug": "gitops"
  },
  {
    "url": "https://glossary.cncf.io/function-as-a-service",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/function-as-a-service.md",
    "title": "Function as a Service (FaaS)",
    "status": "Completed",
    "category": "Technology",
    "tags": [
      "infrastructure"
    ],
    "markdown": "## What it is\n\nFunction as a Service (FaaS) is a type of [serverless](https://glossary.cncf.io/serverless/) [cloud computing](https://glossary.cncf.io/cloud-computing/) [service](https://glossary.cncf.io/service/) \nthat allows executing code in response to events \nwithout maintaining the complex infrastructure \ntypically associated with building and launching [microservices](https://glossary.cncf.io/microservices/) applications. \nWith FaaS, users manage only functions and data while the cloud provider manages the application. \nThis allows developers to get the functions they need without paying for services when code isn’t running.  \n\n## Problem it addresses\n\nIn a traditional on-premises scenario, a business manages and maintains its own data center. \nThe business must invest in servers, storage, software, and other technologies \nand potentially hire an IT staff or contractors to purchase, manage, and upgrade all the equipment and licenses. \nThe data center has to be built to meet peak demand, even when workloads decline and those resources stand idle. \nConversely, if the business grows quickly, the IT department might struggle to keep up. \nUnder a standard [Infrastructure-as-a-Service (IaaS)](https://glossary.cncf.io/infrastructure-as-a-service/) cloud computing model, \nusers pre-purchase capacity units, meaning you pay a public cloud provider for always-on server components to run your apps. \nIt’s the user’s responsibility to scale up server capacity during times of high demand \nand scale down when that capacity is no longer needed. \nThe cloud infrastructure necessary to run an app is active even when the app isn’t being used.\n\n## How it helps\n\nFaaS gives developers an [abstraction](https://glossary.cncf.io/abstraction/) for running web applications in response to events without managing servers. \nFor example, uploading a file could trigger custom code that transcodes the file into various formats. \nFaaS infrastructure will auto-scale the code for heavy use, \nand the developer does not have to spend any time or resources building the code for [scalability](https://glossary.cncf.io/scalability/). \nBilling is based on computation time alone, which means businesses do not have to pay when the functions are not in use.\n",
    "what_it_is": "Function as a Service (FaaS) is a type of [serverless](https://glossary.cncf.io/serverless/) [cloud computing](https://glossary.cncf.io/cloud-computing/) [service](https://glossary.cncf.io/service/) \nthat allows executing code in response to events \nwithout maintaining the complex infrastructure \ntypically associated with building and launching [microservices](https://glossary.cncf.io/microservices/) applications. \nWith FaaS, users manage only functions and data while the cloud provider manages the application. \nThis allows developers to get the functions they need without paying for services when code isn’t running.",
    "problem_it_addresses": "In a traditional on-premises scenario, a business manages and maintains its own data center. \nThe business must invest in servers, storage, software, and other technologies \nand potentially hire an IT staff or contractors to purchase, manage, and upgrade all the equipment and licenses. \nThe data center has to be built to meet peak demand, even when workloads decline and those resources stand idle. \nConversely, if the business grows quickly, the IT department might struggle to keep up. \nUnder a standard [Infrastructure-as-a-Service (IaaS)](https://glossary.cncf.io/infrastructure-as-a-service/) cloud computing model, \nusers pre-purchase capacity units, meaning you pay a public cloud provider for always-on server components to run your apps. \nIt’s the user’s responsibility to scale up server capacity during times of high demand \nand scale down when that capacity is no longer needed. \nThe cloud infrastructure necessary to run an app is active even when the app isn’t being used.",
    "how_it_helps": "FaaS gives developers an [abstraction](https://glossary.cncf.io/abstraction/) for running web applications in response to events without managing servers. \nFor example, uploading a file could trigger custom code that transcodes the file into various formats. \nFaaS infrastructure will auto-scale the code for heavy use, \nand the developer does not have to spend any time or resources building the code for [scalability](https://glossary.cncf.io/scalability/). \nBilling is based on computation time alone, which means businesses do not have to pay when the functions are not in use.",
    "slug": "function-as-a-service"
  },
  {
    "url": "https://glossary.cncf.io/firewall",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/firewall.md",
    "title": "Firewall",
    "status": "Deprecated",
    "draft": true,
    "category": "Technology",
    "tags": [],
    "markdown": "## What it is\n\nA firewall is a system that filters network traffic on the basis of specified rules. \nFirewalls can be hardware, software, or a combination of the two.\n\n## Problem it addresses\n\nBy default, a network will allow anyone to enter and depart as long as they follow the network's routing rules. \nBecause of this default behavior, securing a network is challenging. \nFor example, in a [microservices](https://glossary.cncf.io/microservices/)-based banking app, the services communicate with one another \nby transmitting highly sensitive financial data through their network. \nA malicious actor may infiltrate the network, intercept communication, and do damage if there was no firewall in place.\n \n## How it helps\n\nA firewall examines network traffic using pre-defined rules. \nAll traffic is filtered, and any traffic coming from untrustworthy or suspect sources is blocked \n— only traffic configured to be accepted gets in. \nFirewalls establish a barrier between secured and controlled internal trusted networks. \n",
    "what_it_is": "A firewall is a system that filters network traffic on the basis of specified rules. \nFirewalls can be hardware, software, or a combination of the two.",
    "problem_it_addresses": "By default, a network will allow anyone to enter and depart as long as they follow the network's routing rules. \nBecause of this default behavior, securing a network is challenging. \nFor example, in a [microservices](https://glossary.cncf.io/microservices/)-based banking app, the services communicate with one another \nby transmitting highly sensitive financial data through their network. \nA malicious actor may infiltrate the network, intercept communication, and do damage if there was no firewall in place.",
    "how_it_helps": "A firewall examines network traffic using pre-defined rules. \nAll traffic is filtered, and any traffic coming from untrustworthy or suspect sources is blocked \n— only traffic configured to be accepted gets in. \nFirewalls establish a barrier between secured and controlled internal trusted networks.",
    "slug": "firewall"
  },
  {
    "url": "https://glossary.cncf.io/event-streaming",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/event-streaming.md",
    "title": "Event Streaming",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology",
      "networking"
    ],
    "markdown": "## What it is\n\nEvent streaming is an approach where software sends event data from one application to another to continuously communicate what they are doing.\nPicture a service broadcasting everything it does to all other services.\nEach activity taken by a service is referred to as an event, hence event streaming.\nFor example, NASDAQ gets updates on stock and commodities pricing every second.\nIf you had an application that monitored a specific set of stocks, you would want to receive that information in near real-time.\nYahoo! Finance provides an [API](https://glossary.cncf.io/application-programming-interface/) that pulls from NASDAQ and sends (or streams) the information (or events) from their application to any application that subscribes to it.\nThe data being sent as well as the changes in that data (stock prices) are the events while the process of delivering them to an application is event streaming.\n\n## Problem it addresses\n\nTraditionally, Yahoo! Finance would use single TCP requests.\nThis would be very inefficient as it would require a connection to be created for every event.\nAs data becomes more real-time in nature, scaling such a solution becomes inefficient.\nOpening a connection once and allowing events to flow is ideal for real-time collection.\nThe amount of data being generated is growing exponentially and with that, the data state is in constant flux. Developers and users need to be able to see that data in near real-time.\n\n## How it helps\n\nEvent streaming allows data changes to be communicated from source to receiver.\nInstead of waiting for services to request information, the service continuously streams all its events (or activities).\nIt isn't concerned about what happens to the information.\nIt just does what it needs to do and broadcasts it, thus remaining completely independent of any other service.\n",
    "what_it_is": "Event streaming is an approach where software sends event data from one application to another to continuously communicate what they are doing.\nPicture a service broadcasting everything it does to all other services.\nEach activity taken by a service is referred to as an event, hence event streaming.\nFor example, NASDAQ gets updates on stock and commodities pricing every second.\nIf you had an application that monitored a specific set of stocks, you would want to receive that information in near real-time.\nYahoo! Finance provides an [API](https://glossary.cncf.io/application-programming-interface/) that pulls from NASDAQ and sends (or streams) the information (or events) from their application to any application that subscribes to it.\nThe data being sent as well as the changes in that data (stock prices) are the events while the process of delivering them to an application is event streaming.",
    "problem_it_addresses": "Traditionally, Yahoo! Finance would use single TCP requests.\nThis would be very inefficient as it would require a connection to be created for every event.\nAs data becomes more real-time in nature, scaling such a solution becomes inefficient.\nOpening a connection once and allowing events to flow is ideal for real-time collection.\nThe amount of data being generated is growing exponentially and with that, the data state is in constant flux. Developers and users need to be able to see that data in near real-time.",
    "how_it_helps": "Event streaming allows data changes to be communicated from source to receiver.\nInstead of waiting for services to request information, the service continuously streams all its events (or activities).\nIt isn't concerned about what happens to the information.\nIt just does what it needs to do and broadcasts it, thus remaining completely independent of any other service.",
    "slug": "event-streaming"
  },
  {
    "url": "https://glossary.cncf.io/event-driven-architecture",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/event-driven-architecture.md",
    "title": "Event-Driven Architecture",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "architecture"
    ],
    "markdown": "## What it is\n\nEvent-driven architecture is a software architecture that promotes the creation, processing, and consumption of events.\nAn event is any change to an application's state.\nFor example, hailing a ride on a ride-sharing app represents an event.\nThis architecture creates the structure in which events can be properly routed from their source (the app requesting a ride) to the desired receivers (the apps of available drivers nearby).\n\n## Problem it addresses\n\nAs more data becomes real-time, finding reliable ways to ensure that events are captured and routed to the appropriate [service](https://glossary.cncf.io/service/) that must process event requests gets increasingly challenging.\nTraditional methods of handling events often have no way to guarantee that messages are appropriately routed or were actually sent or received.\nAs applications begin to scale, it becomes more challenging to orchestrate events.\n\n## How it helps\n\nEvent-driven architectures establish a central hub for all events (e.g., Kafka).\nYou then define the event producers (source) and consumers (receiver), and the central event hub guarantees the flow of events.\nThis architecture ensures that services remain decoupled and events are properly routed from the producer to the consumer.\nThe producer will take the incoming event, usually by HTTP protocol, then route the event information.\n",
    "what_it_is": "Event-driven architecture is a software architecture that promotes the creation, processing, and consumption of events.\nAn event is any change to an application's state.\nFor example, hailing a ride on a ride-sharing app represents an event.\nThis architecture creates the structure in which events can be properly routed from their source (the app requesting a ride) to the desired receivers (the apps of available drivers nearby).",
    "problem_it_addresses": "As more data becomes real-time, finding reliable ways to ensure that events are captured and routed to the appropriate [service](https://glossary.cncf.io/service/) that must process event requests gets increasingly challenging.\nTraditional methods of handling events often have no way to guarantee that messages are appropriately routed or were actually sent or received.\nAs applications begin to scale, it becomes more challenging to orchestrate events.",
    "how_it_helps": "Event-driven architectures establish a central hub for all events (e.g., Kafka).\nYou then define the event producers (source) and consumers (receiver), and the central event hub guarantees the flow of events.\nThis architecture ensures that services remain decoupled and events are properly routed from the producer to the consumer.\nThe producer will take the incoming event, usually by HTTP protocol, then route the event information.",
    "slug": "event-driven-architecture"
  },
  {
    "url": "https://glossary.cncf.io/edge-computing",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/edge-computing.md",
    "title": "Edge Computing",
    "status": "Completed",
    "category": "Technology",
    "markdown": "## What it is\n\nEdge computing is a [distributed system](https://glossary.cncf.io/distributed-systems/) approach that shifts some storage and computing capacity from the primary data center to the data source.\nThe gathered data is computed locally (e.g., on a factory floor, in a store, or throughout a city) rather than sent to a centralized data center for processing and analysis. \nThese local processing units or devices represent the system's edge, whereas the data center is its center.\nThe output computed at the edge is then sent back to the primary data center for further processing.\nExamples of edge computing include wrists gadgets or computers that analyze traffic flow.\n\n## Problem it addresses\n\nOver the past decade, we've seen an increasing amount of edge devices (e.g., mobile phones, smart watches, or sensors). \nIn some cases, real-time data processing is not only a nice-to-have but vital. \nThink of self-driving cars. \nNow imagine the data from the car's sensors would have to be transferred to a data center for processing before being sent back to the vehicle so it can react appropriately. \nThe inherent network latency could be fatal. \nWhile this is an extreme example, most users wouldn't want to use a smart device unable to provide instant feedback. \n\n## How it helps\n\nAs described above, for edge devices to be useful, they must do at least part of the processing and analyzing locally to provide near real-time feedback to users. \nThis is achieved by shifting some storage and processing resources from the data center to where the data is generated: the edge device.\nProcessed and unprocessed data is subsequently sent to the data center for further processing and storage.\nIn short, efficiency and speed are the primary drivers of edge computing. \n\n\n",
    "what_it_is": "Edge computing is a [distributed system](https://glossary.cncf.io/distributed-systems/) approach that shifts some storage and computing capacity from the primary data center to the data source.\nThe gathered data is computed locally (e.g., on a factory floor, in a store, or throughout a city) rather than sent to a centralized data center for processing and analysis. \nThese local processing units or devices represent the system's edge, whereas the data center is its center.\nThe output computed at the edge is then sent back to the primary data center for further processing.\nExamples of edge computing include wrists gadgets or computers that analyze traffic flow.",
    "problem_it_addresses": "Over the past decade, we've seen an increasing amount of edge devices (e.g., mobile phones, smart watches, or sensors). \nIn some cases, real-time data processing is not only a nice-to-have but vital. \nThink of self-driving cars. \nNow imagine the data from the car's sensors would have to be transferred to a data center for processing before being sent back to the vehicle so it can react appropriately. \nThe inherent network latency could be fatal. \nWhile this is an extreme example, most users wouldn't want to use a smart device unable to provide instant feedback.",
    "how_it_helps": "As described above, for edge devices to be useful, they must do at least part of the processing and analyzing locally to provide near real-time feedback to users. \nThis is achieved by shifting some storage and processing resources from the data center to where the data is generated: the edge device.\nProcessed and unprocessed data is subsequently sent to the data center for further processing and storage.\nIn short, efficiency and speed are the primary drivers of edge computing.",
    "slug": "edge-computing"
  },
  {
    "url": "https://glossary.cncf.io/distributed-systems",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/distributed-systems.md",
    "title": "Distributed System",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "architecture"
    ],
    "markdown": "## What it is\n\nA distributed system is a collection of autonomous computing elements \nconnected over a network that appears to users as a single coherent system. \nGenerally referred to as [nodes](https://glossary.cncf.io/nodes/), these components can be hardware devices (e.g. computers, mobile phones) or software processes. \nNodes are programmed to achieve a common goal and, to collaborate, they exchange messages over the network. \n\n## Problem it addresses\n\nNumerous modern applications today are so big they'd need supercomputers to operate. \nThink Gmail or Netflix. No single computer is powerful enough to host the entire application. \nBy connecting multiple computers, compute power becomes nearly limitless. \nWithout distributed computing, many applications we rely on today wouldn't be possible. \n\nTraditionally, systems would [scale](https://glossary.cncf.io/scalability/) vertically. \nThat's when you add more CPU or memory to an individual machine. \nVertical scaling is time-consuming, requires downtime, and reaches its limit quickly. \n\n## How it helps\n\nDistributed systems allow for [horizontal scaling](https://glossary.cncf.io/horizontal-scaling/) (e.g. adding more nodes to the system whenever needed). \nThis can be automated allowing a system to handle a sudden increase in workload or resource consumption. \n\nA non-distributed system exposes itself to risks of failure because if one machine fails, the entire system fails. \nA distributed system can be designed in such a way that, \neven if some machines go down, the overall system can still keep working to produce the same result.\n",
    "what_it_is": "A distributed system is a collection of autonomous computing elements \nconnected over a network that appears to users as a single coherent system. \nGenerally referred to as [nodes](https://glossary.cncf.io/nodes/), these components can be hardware devices (e.g. computers, mobile phones) or software processes. \nNodes are programmed to achieve a common goal and, to collaborate, they exchange messages over the network.",
    "problem_it_addresses": "Numerous modern applications today are so big they'd need supercomputers to operate. \nThink Gmail or Netflix. No single computer is powerful enough to host the entire application. \nBy connecting multiple computers, compute power becomes nearly limitless. \nWithout distributed computing, many applications we rely on today wouldn't be possible. \n\nTraditionally, systems would [scale](https://glossary.cncf.io/scalability/) vertically. \nThat's when you add more CPU or memory to an individual machine. \nVertical scaling is time-consuming, requires downtime, and reaches its limit quickly.",
    "how_it_helps": "Distributed systems allow for [horizontal scaling](https://glossary.cncf.io/horizontal-scaling/) (e.g. adding more nodes to the system whenever needed). \nThis can be automated allowing a system to handle a sudden increase in workload or resource consumption. \n\nA non-distributed system exposes itself to risks of failure because if one machine fails, the entire system fails. \nA distributed system can be designed in such a way that, \neven if some machines go down, the overall system can still keep working to produce the same result.",
    "slug": "distributed-systems"
  },
  {
    "url": "https://glossary.cncf.io/distributed-apps",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/distributed-apps.md",
    "title": "Distributed Apps",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "architecture"
    ],
    "markdown": "## What it is\n\nA distributed application is an application where the functionality is broken down into multiple smaller independent parts. \nDistributed applications are usually composed of individual [microservices](https://glossary.cncf.io/microservices/) \nthat handle different concerns within the broader application. \nIn a cloud native environment, the individual components typically run as [containers](https://glossary.cncf.io/container/) on a [cluster](https://glossary.cncf.io/cluster/). \n\n## Problem it addresses \n\nAn application running on one single computer represents a single point of failure — if that computer fails, the application becomes unavailable. \nDistributed applications are often contrasted to [monolithic applications](https://glossary.cncf.io/monolithic-apps/). \nA monolithic app can be harder to scale as the various components can't be scaled independently. \nThey can also become a drag on developer velocity as they grow \nbecause more developers need to work on a shared codebase that doesn't necessarily have well defined boundaries.\n\n## How it helps\n\nWhen splitting an application into different pieces and running them in many places, the overall system can tolerate more failures. \nIt also allows an application to take advantage of scaling features not available to a single application instance, \nnamely the ability to [scale horizontally](https://glossary.cncf.io/horizontal-scaling/). \nThis does, however, come at a cost: increased complexity and operational overhead \n— you’re now running lots of application components instead of one app.\n",
    "what_it_is": "A distributed application is an application where the functionality is broken down into multiple smaller independent parts. \nDistributed applications are usually composed of individual [microservices](https://glossary.cncf.io/microservices/) \nthat handle different concerns within the broader application. \nIn a cloud native environment, the individual components typically run as [containers](https://glossary.cncf.io/container/) on a [cluster](https://glossary.cncf.io/cluster/).",
    "problem_it_addresses": "An application running on one single computer represents a single point of failure — if that computer fails, the application becomes unavailable. \nDistributed applications are often contrasted to [monolithic applications](https://glossary.cncf.io/monolithic-apps/). \nA monolithic app can be harder to scale as the various components can't be scaled independently. \nThey can also become a drag on developer velocity as they grow \nbecause more developers need to work on a shared codebase that doesn't necessarily have well defined boundaries.",
    "how_it_helps": "When splitting an application into different pieces and running them in many places, the overall system can tolerate more failures. \nIt also allows an application to take advantage of scaling features not available to a single application instance, \nnamely the ability to [scale horizontally](https://glossary.cncf.io/horizontal-scaling/). \nThis does, however, come at a cost: increased complexity and operational overhead \n— you’re now running lots of application components instead of one app.",
    "slug": "distributed-apps"
  },
  {
    "url": "https://glossary.cncf.io/digital-certificate",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/digital-certificate.md",
    "title": "Digital Certificate",
    "status": "Feedback Appreciated",
    "category": "technology",
    "tags": [
      "security"
    ],
    "markdown": "## What it is\n\nA (digital) certificate — also often referred to as a public key certificate, or SSL certificate — is a digital document used to help secure communications over the network. \nCertificates allow us to know that the particular entity we're communicating with is who they say they are.\nThey also allow us to ensure that our communications are private by encrypting the data we send and receive.\n\n## Problem it addresses\n\nWhen devices communicate over a network there is no inherent guarantee that a particular device is who it says it is.\nAdditionally, we can't guarantee that the traffic between any two devices won't be intercepted by a third party.\nConsequently, any communication can potentially be intercepted, compromising sensitive information like usernames and passwords. \n\n## How it helps\n\nModern email clients that utilize certificates can notify you if a sender's identity is correct, as will web browsers (notice the little lock in front of the address bar of your web browser).\nOn the other side, certificates can be used to encrypt communication between entities on the internet.\nThey provide an encryption technique that makes it nearly impossible, for someone who intercepts the communication, to actually read the data.\n",
    "what_it_is": "A (digital) certificate — also often referred to as a public key certificate, or SSL certificate — is a digital document used to help secure communications over the network. \nCertificates allow us to know that the particular entity we're communicating with is who they say they are.\nThey also allow us to ensure that our communications are private by encrypting the data we send and receive.",
    "problem_it_addresses": "When devices communicate over a network there is no inherent guarantee that a particular device is who it says it is.\nAdditionally, we can't guarantee that the traffic between any two devices won't be intercepted by a third party.\nConsequently, any communication can potentially be intercepted, compromising sensitive information like usernames and passwords.",
    "how_it_helps": "Modern email clients that utilize certificates can notify you if a sender's identity is correct, as will web browsers (notice the little lock in front of the address bar of your web browser).\nOn the other side, certificates can be used to encrypt communication between entities on the internet.\nThey provide an encryption technique that makes it nearly impossible, for someone who intercepts the communication, to actually read the data.",
    "slug": "digital-certificate"
  },
  {
    "url": "https://glossary.cncf.io/devsecops",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/devsecops.md",
    "title": "DevSecOps",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology",
      "security"
    ],
    "markdown": "## What it is\n\nThe term DevSecOps refers to a cultural merger of the development, operational, and security responsibilities. \nIt extends the [DevOps](https://glossary.cncf.io/devops/) approach to include security priorities \nwith minimal to no disruption in the developer and operational workflow. \nLike DevOps, DevSecOps is a cultural shift, pushed by the technologies adopted, with unique adoption methods.\n\n## Problem it addresses\n\nDevOps practices include [continuous integration](https://glossary.cncf.io/continuous-integration/) and [continuous deployment](https://glossary.cncf.io/continuous-delivery/) \nand accelerate application development and release cycles. \nUnfortunately, automated release processes that fail to represent \nall organizational stakeholders adequately can exacerbate existing issues. \nA process that rapidly releases new software without considering security needs \ncan degrade an organizations’ security posture.\n\n## How it helps\n\nDevSecOps focuses on breaking down team silos and promotes the creation of secure, automated workflows. \nWhen selecting security applications, organizations must take advantage of \nautomated CI/CD workflows and policy enforcement that empower the developer. \nThe goal is not to be a blocker but to enforce security policies \nwhile giving users accurate information on how to move their project forward. \nWhen properly implemented, an organization will gain better team communication and \nreduce security mishaps and associated costs.\n",
    "what_it_is": "The term DevSecOps refers to a cultural merger of the development, operational, and security responsibilities. \nIt extends the [DevOps](https://glossary.cncf.io/devops/) approach to include security priorities \nwith minimal to no disruption in the developer and operational workflow. \nLike DevOps, DevSecOps is a cultural shift, pushed by the technologies adopted, with unique adoption methods.",
    "problem_it_addresses": "DevOps practices include [continuous integration](https://glossary.cncf.io/continuous-integration/) and [continuous deployment](https://glossary.cncf.io/continuous-delivery/) \nand accelerate application development and release cycles. \nUnfortunately, automated release processes that fail to represent \nall organizational stakeholders adequately can exacerbate existing issues. \nA process that rapidly releases new software without considering security needs \ncan degrade an organizations’ security posture.",
    "how_it_helps": "DevSecOps focuses on breaking down team silos and promotes the creation of secure, automated workflows. \nWhen selecting security applications, organizations must take advantage of \nautomated CI/CD workflows and policy enforcement that empower the developer. \nThe goal is not to be a blocker but to enforce security policies \nwhile giving users accurate information on how to move their project forward. \nWhen properly implemented, an organization will gain better team communication and \nreduce security mishaps and associated costs.",
    "slug": "devsecops"
  },
  {
    "url": "https://glossary.cncf.io/devops",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/devops.md",
    "title": "DevOps",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology"
    ],
    "markdown": "## What it is\n\nDevOps is a methodology in which teams own the entire process from application development to production operations, hence DevOps. \nIt goes beyond implementing a set of technologies and requires a complete shift in culture and processes. \nDevOps calls for groups of engineers that work on small components (versus an entire feature), decreasing handoffs – a common source of errors. \n\n## Problem it addresses\n\nTraditionally, in complex organizations with [tightly-coupled](https://glossary.cncf.io/tightly-coupled-architectures/) [monolithic apps](https://glossary.cncf.io/monolithic-apps/), \nwork was generally fragmented between multiple groups. \nThis led to numerous handoffs and long lead times. \nEach time a component or update was ready, it was placed in a queue for the next team. \nBecause individuals only worked on one small piece of the project, this approach led to a lack of ownership. \nTheir goal was to get the work to the next group, not deliver the right functionality to the customer \n— a clear misalignment of priorities. \n\nBy the time code finally got into production, it went through so many developers, \nwaiting in so many queues that it was difficult to trace the origin of the problem if the code didn’t work. \nDevOps turns this approach upside down.\n\n## How it helps\n\nHaving one team own the entire lifecycle of an application results in \nminimized handoffs, reduce risk when deploying into production, better code quality \nas teams are also responsible for how code performs in production \nand increased employee satisfaction due to more autonomy and ownership.\n",
    "what_it_is": "DevOps is a methodology in which teams own the entire process from application development to production operations, hence DevOps. \nIt goes beyond implementing a set of technologies and requires a complete shift in culture and processes. \nDevOps calls for groups of engineers that work on small components (versus an entire feature), decreasing handoffs – a common source of errors.",
    "problem_it_addresses": "Traditionally, in complex organizations with [tightly-coupled](https://glossary.cncf.io/tightly-coupled-architectures/) [monolithic apps](https://glossary.cncf.io/monolithic-apps/), \nwork was generally fragmented between multiple groups. \nThis led to numerous handoffs and long lead times. \nEach time a component or update was ready, it was placed in a queue for the next team. \nBecause individuals only worked on one small piece of the project, this approach led to a lack of ownership. \nTheir goal was to get the work to the next group, not deliver the right functionality to the customer \n— a clear misalignment of priorities. \n\nBy the time code finally got into production, it went through so many developers, \nwaiting in so many queues that it was difficult to trace the origin of the problem if the code didn’t work. \nDevOps turns this approach upside down.",
    "how_it_helps": "Having one team own the entire lifecycle of an application results in \nminimized handoffs, reduce risk when deploying into production, better code quality \nas teams are also responsible for how code performs in production \nand increased employee satisfaction due to more autonomy and ownership.",
    "slug": "devops"
  },
  {
    "url": "https://glossary.cncf.io/debugging",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/debugging.md",
    "title": "Debugging",
    "status": "Deprecated",
    "category": "concept",
    "draft": true,
    "tags": [
      "application",
      "methodology"
    ],
    "markdown": "## What it is\n\nDebugging is the process or activity of finding and resolving bugs (or errors) from computer programs, software, or systems to get the desired result. \nA bug is a defect or a problem leading to incorrect or unexpected results.\n\n## Problem it addresses\n\nSoftware development is a complex activity that makes it nearly impossible to write code without introducing bugs. \nThose bugs lead to code that will likely not function as desired (undefined behavior) when executed. \nDepending on how critical an application is, bugs can have a significant negative impact — financially or even on human lives. \nUsually, application code has to go through different stages or environments where it gets tested. \nThe more critical an application is, the more accurate the testing has to be. \n\n## How it helps\n\nWhen bugs appear, engineers have to debug (e.g., finding and fixing) the app to decrease undesired behavior for production systems. \nDebugging is no easy task as engineers have to track down the source of the undesired behavior. \nIt requires knowledge about the code itself and the execution context at runtime. \nThis is where different debugging techniques and tools come in handy. \nAnalysis of logs, traces, and metrics, for instance, are used for debugging directly in production. \nDevelopers can use interactive debugging to step through the code at runtime while analyzing the related execution context. \nOnce they have identified the source of the failure, they correct the code and create a bug fix or patch.\n",
    "what_it_is": "Debugging is the process or activity of finding and resolving bugs (or errors) from computer programs, software, or systems to get the desired result. \nA bug is a defect or a problem leading to incorrect or unexpected results.",
    "problem_it_addresses": "Software development is a complex activity that makes it nearly impossible to write code without introducing bugs. \nThose bugs lead to code that will likely not function as desired (undefined behavior) when executed. \nDepending on how critical an application is, bugs can have a significant negative impact — financially or even on human lives. \nUsually, application code has to go through different stages or environments where it gets tested. \nThe more critical an application is, the more accurate the testing has to be.",
    "how_it_helps": "When bugs appear, engineers have to debug (e.g., finding and fixing) the app to decrease undesired behavior for production systems. \nDebugging is no easy task as engineers have to track down the source of the undesired behavior. \nIt requires knowledge about the code itself and the execution context at runtime. \nThis is where different debugging techniques and tools come in handy. \nAnalysis of logs, traces, and metrics, for instance, are used for debugging directly in production. \nDevelopers can use interactive debugging to step through the code at runtime while analyzing the related execution context. \nOnce they have identified the source of the failure, they correct the code and create a bug fix or patch.",
    "slug": "debugging"
  },
  {
    "url": "https://glossary.cncf.io/database-as-a-service",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/database-as-a-service.md",
    "title": "Database as a Service (DBaaS)",
    "status": "Deprecated",
    "category": "Technology",
    "draft": true,
    "tags": [],
    "markdown": "## What it is\n\nDatabase-as-a-Service (DBaaS) is a service managed by a [cloud](https://glossary.cncf.io/cloud-computing/) operator (public or private) \nthat supports applications without requiring the application team to \nperform traditional database administration functions. \nDBaaS allows app developers to leverage databases without being experts or \nhiring a database administrator (DBA) to keep the database up to date.\n\n## Problem it addresses \n\nTraditionally, in on-premise setups, organizations regularly have to invest in \nadditional storage and processing capacity to accommodate database expansion which can be expensive. \nAdditionally, developers provision and configure databases with the help of IT infrastructure teams, \nslowing deployment speed of database-driven applications down. \nLoading and executing them also takes longer.\n\n## How it helps\n\nDBaaS allows developers to outsource all administration/administrative operations to the cloud-based service provider. \nThe service provider ensures the database is running smoothly, \nincluding configuration management, backups, patches, upgrades, service monitoring, and more, \nwith a user-friendly interface to manage it all. \nDBaaS helps organizations develop enterprise-grade applications faster while minimizing database costs.\n",
    "what_it_is": "Database-as-a-Service (DBaaS) is a service managed by a [cloud](https://glossary.cncf.io/cloud-computing/) operator (public or private) \nthat supports applications without requiring the application team to \nperform traditional database administration functions. \nDBaaS allows app developers to leverage databases without being experts or \nhiring a database administrator (DBA) to keep the database up to date.",
    "problem_it_addresses": "Traditionally, in on-premise setups, organizations regularly have to invest in \nadditional storage and processing capacity to accommodate database expansion which can be expensive. \nAdditionally, developers provision and configure databases with the help of IT infrastructure teams, \nslowing deployment speed of database-driven applications down. \nLoading and executing them also takes longer.",
    "how_it_helps": "DBaaS allows developers to outsource all administration/administrative operations to the cloud-based service provider. \nThe service provider ensures the database is running smoothly, \nincluding configuration management, backups, patches, upgrades, service monitoring, and more, \nwith a user-friendly interface to manage it all. \nDBaaS helps organizations develop enterprise-grade applications faster while minimizing database costs.",
    "slug": "database-as-a-service"
  },
  {
    "url": "https://glossary.cncf.io/data-center",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/data-center.md",
    "title": "Datacenter",
    "status": "Completed",
    "category": "Technology",
    "tags": [
      "infrastructure",
      "fundamental"
    ],
    "markdown": "## What it is\n\nA datacenter is a specialized building or facility designed to house computers, most often servers. \nThese datacenters tend to be connected to high-speed internet lines, especially when focused on [cloud computing](https://glossary.cncf.io/cloud-computing/). \nThe buildings housing datacenters are equipped to maintain service even during adverse events, including generators that provide power during outages and powerful air conditioning that keep the heat-producing computers cool. \n\n## Problem it addresses\n\nBefore datacenters became prevalent in the late 1990ies, there were mainly individual computers with specific tasks or those used by individuals to do their work.\n\nBut computers have limited resources (disk, RAM, and CPU). \nThat means that applications running on them have the same hard constraints, limiting the kinds of applications it can run.\nBefore datacenters, the scale of the application was constrained by the capacity of the computer it was running on. \nBut if you think about apps at scale like Gmail or Netflix (the app, not the user interface you have on your phone or computer), those need more computing capacity than any one computer can provide. \nAnd that's where datacenters come in. \n\n## How it helps\n\nBy connecting various servers, users can create a [distributed system](https://glossary.cncf.io/distributed-systems/) that functions like a \"supercomputer.\" \nBecause we are bundling the power of several machines, we can now run much bigger apps or process much more powerful computational tasks.\nDatacenters power most applications we use on a daily basis. \n\n[Public clouds](https://glossary.cncf.io/cloud-computing/) are datacenters that rent out capacity to their clients. \nOver the past years, we have seen a move from enterprise-owned datacenters to the cloud. \n",
    "what_it_is": "A datacenter is a specialized building or facility designed to house computers, most often servers. \nThese datacenters tend to be connected to high-speed internet lines, especially when focused on [cloud computing](https://glossary.cncf.io/cloud-computing/). \nThe buildings housing datacenters are equipped to maintain service even during adverse events, including generators that provide power during outages and powerful air conditioning that keep the heat-producing computers cool.",
    "problem_it_addresses": "Before datacenters became prevalent in the late 1990ies, there were mainly individual computers with specific tasks or those used by individuals to do their work.\n\nBut computers have limited resources (disk, RAM, and CPU). \nThat means that applications running on them have the same hard constraints, limiting the kinds of applications it can run.\nBefore datacenters, the scale of the application was constrained by the capacity of the computer it was running on. \nBut if you think about apps at scale like Gmail or Netflix (the app, not the user interface you have on your phone or computer), those need more computing capacity than any one computer can provide. \nAnd that's where datacenters come in.",
    "how_it_helps": "By connecting various servers, users can create a [distributed system](https://glossary.cncf.io/distributed-systems/) that functions like a \"supercomputer.\" \nBecause we are bundling the power of several machines, we can now run much bigger apps or process much more powerful computational tasks.\nDatacenters power most applications we use on a daily basis. \n\n[Public clouds](https://glossary.cncf.io/cloud-computing/) are datacenters that rent out capacity to their clients. \nOver the past years, we have seen a move from enterprise-owned datacenters to the cloud.",
    "slug": "data-center"
  },
  {
    "url": "https://glossary.cncf.io/continuous-integration",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/continuous-integration.md",
    "title": "Continuous integration (CI)",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "application",
      "methodology"
    ],
    "markdown": "## What it is \n\nContinuous integration, often abbreviated as CI, is the practice of integrating code changes as regularly as possible. \nCI is a prerequisite for [continuous delivery](https://glossary.cncf.io/continuous-delivery/) (CD). \nTraditionally, the CI process begins when code changes are committed to a source control system (Git, Mercurial, or Subversion) \nand ends with a tested artifact ready to be consumed by a CD system. \n\n## Problem it addresses\n\nSoftware systems are often large and complex, with numerous developers maintaining and updating them. \nWorking in parallel on different parts of the system, \nthese developers may make conflicting changes and inadvertently break each other’s work. \nAdditionally, with multiple developers working on the same project, \nany everyday tasks such as testing and calculating code quality would need to be repeated by each developer, wasting time.\n\n## How it helps\n\nCI software automatically checks that code changes merge cleanly whenever a developer commits a change. \nIt's a near-ubiquitous practice to use the CI server to run code quality checks, tests, and even deployments. \nAs such, it becomes a concrete implementation of quality control within teams. \nCI allows software teams to turn every code commit into either a concrete failure or a viable release candidate.\n\n## Related terms\n\n* [Continuous Delivery](https://glossary.cncf.io/continuous-delivery/)\n* [Continuous Deployment](https://glossary.cncf.io/continuous-deployment/)\n",
    "what_it_is": "Continuous integration, often abbreviated as CI, is the practice of integrating code changes as regularly as possible. \nCI is a prerequisite for [continuous delivery](https://glossary.cncf.io/continuous-delivery/) (CD). \nTraditionally, the CI process begins when code changes are committed to a source control system (Git, Mercurial, or Subversion) \nand ends with a tested artifact ready to be consumed by a CD system.",
    "problem_it_addresses": "Software systems are often large and complex, with numerous developers maintaining and updating them. \nWorking in parallel on different parts of the system, \nthese developers may make conflicting changes and inadvertently break each other’s work. \nAdditionally, with multiple developers working on the same project, \nany everyday tasks such as testing and calculating code quality would need to be repeated by each developer, wasting time.",
    "how_it_helps": "CI software automatically checks that code changes merge cleanly whenever a developer commits a change. \nIt's a near-ubiquitous practice to use the CI server to run code quality checks, tests, and even deployments. \nAs such, it becomes a concrete implementation of quality control within teams. \nCI allows software teams to turn every code commit into either a concrete failure or a viable release candidate.",
    "related_terms": "* [Continuous Delivery](https://glossary.cncf.io/continuous-delivery/)\n* [Continuous Deployment](https://glossary.cncf.io/continuous-deployment/)",
    "slug": "continuous-integration"
  },
  {
    "url": "https://glossary.cncf.io/continuous-deployment",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/continuous-deployment.md",
    "title": "Continuous Deployment (CD)",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "application",
      "methodology"
    ],
    "markdown": "## What it is\n\nContinuous deployment, often abbreviated as CD, goes a step further than [continuous delivery](https://glossary.cncf.io/continuous-delivery/) \nby deploying finished software directly to production. \nContinuous deployment (CD) goes hand in hand with [continuous integration](https://glossary.cncf.io/continuous-integration/) (CI), \nand is often referred to as CI/CD. \nThe CI process tests if the changes to a given application are valid, \nand the CD process automatically deploys the code changes through an organization's environments from test to production.\n\n## Problem it addresses\n\nReleasing new software versions can be a labor-intensive and error-prone process. \nIt is also often something that organizations will only want to do infrequently to avoid production incidents \nand reduce the number of time engineers need to be available outside of regular business hours. \nTraditional software deployment models leave organizations in a vicious cycle \nwhere the process of releasing software fails to meet organizational needs around both stability and feature velocity.\n\n## How it helps\n\nBy automating the release cycle and forcing organizations to release to production more frequently, \nCD does what CI did for development teams for operations teams. \nSpecifically, it forces operations teams to automate the painful and error-prone portions of production deployments, reducing overall risk. \nIt also makes organizations better at accepting and adapting to production changes, which leads to higher stability.\n\n## Related terms\n\n* [Continuous Integration](https://glossary.cncf.io/continuous-integration/)\n* [Continuous Delivery](https://glossary.cncf.io/continuous-delivery/)\n",
    "what_it_is": "Continuous deployment, often abbreviated as CD, goes a step further than [continuous delivery](https://glossary.cncf.io/continuous-delivery/) \nby deploying finished software directly to production. \nContinuous deployment (CD) goes hand in hand with [continuous integration](https://glossary.cncf.io/continuous-integration/) (CI), \nand is often referred to as CI/CD. \nThe CI process tests if the changes to a given application are valid, \nand the CD process automatically deploys the code changes through an organization's environments from test to production.",
    "problem_it_addresses": "Releasing new software versions can be a labor-intensive and error-prone process. \nIt is also often something that organizations will only want to do infrequently to avoid production incidents \nand reduce the number of time engineers need to be available outside of regular business hours. \nTraditional software deployment models leave organizations in a vicious cycle \nwhere the process of releasing software fails to meet organizational needs around both stability and feature velocity.",
    "how_it_helps": "By automating the release cycle and forcing organizations to release to production more frequently, \nCD does what CI did for development teams for operations teams. \nSpecifically, it forces operations teams to automate the painful and error-prone portions of production deployments, reducing overall risk. \nIt also makes organizations better at accepting and adapting to production changes, which leads to higher stability.",
    "related_terms": "* [Continuous Integration](https://glossary.cncf.io/continuous-integration/)\n* [Continuous Delivery](https://glossary.cncf.io/continuous-delivery/)",
    "slug": "continuous-deployment"
  },
  {
    "url": "https://glossary.cncf.io/continuous-delivery",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/continuous-delivery.md",
    "title": "Continuous Delivery (CD)",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology",
      "application"
    ],
    "markdown": "## What it is\n\nContinuous delivery, often abbreviated as  CD, is a set of practices \nin which code changes are automatically deployed into an acceptance environment \n(or, in the case of continuous deployment, into production). \nCD crucially includes procedures to ensure that software is adequately tested \nbefore deployment and provides a way to rollback changes if deemed necessary. \nContinuous integration (CI) is the first step towards continuous delivery \n(i.e., changes have to merge cleanly before being tested and deployed).\n\n## Problem it addresses\n\nDeploying [reliable](https://glossary.cncf.io/reliability/) updates becomes a problem at scale. \nIdeally, we'd deploy more frequently to deliver better value to end-users. \nHowever, doing it manually translates into high transaction costs for every change. \nHistorically, to avoid these costs, organizations have released less frequently, \ndeploying more changes at once and increasing the risk that something goes wrong.\n\n## How it helps\n\nCD strategies create a fully automated path to production \nthat tests and deploys the software using various deployment strategies \nsuch as [canary](https://glossary.cncf.io/canary-deployment/) or [blue-green](https://glossary.cncf.io/blue-green-deployment/) releases. \nThis allows developers to deploy code frequently,  giving them peace of mind that the new revision has been tested. \nTypically, trunk-based development is used in CD strategies as opposed to feature branching or pull requests.\n\n## Related terms\n\n* [Continuous Integration](https://glossary.cncf.io/continuous-integration/)\n* [Continuous Deployment](https://glossary.cncf.io/continuous-deployment/)\n",
    "what_it_is": "Continuous delivery, often abbreviated as  CD, is a set of practices \nin which code changes are automatically deployed into an acceptance environment \n(or, in the case of continuous deployment, into production). \nCD crucially includes procedures to ensure that software is adequately tested \nbefore deployment and provides a way to rollback changes if deemed necessary. \nContinuous integration (CI) is the first step towards continuous delivery \n(i.e., changes have to merge cleanly before being tested and deployed).",
    "problem_it_addresses": "Deploying [reliable](https://glossary.cncf.io/reliability/) updates becomes a problem at scale. \nIdeally, we'd deploy more frequently to deliver better value to end-users. \nHowever, doing it manually translates into high transaction costs for every change. \nHistorically, to avoid these costs, organizations have released less frequently, \ndeploying more changes at once and increasing the risk that something goes wrong.",
    "how_it_helps": "CD strategies create a fully automated path to production \nthat tests and deploys the software using various deployment strategies \nsuch as [canary](https://glossary.cncf.io/canary-deployment/) or [blue-green](https://glossary.cncf.io/blue-green-deployment/) releases. \nThis allows developers to deploy code frequently,  giving them peace of mind that the new revision has been tested. \nTypically, trunk-based development is used in CD strategies as opposed to feature branching or pull requests.",
    "related_terms": "* [Continuous Integration](https://glossary.cncf.io/continuous-integration/)\n* [Continuous Deployment](https://glossary.cncf.io/continuous-deployment/)",
    "slug": "continuous-delivery"
  },
  {
    "url": "https://glossary.cncf.io/containers-as-a-service",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/containers-as-a-service.md",
    "title": "Containers as a Service",
    "status": "Deprecated",
    "category": "Technology",
    "draft": true,
    "tags": [
      "platform"
    ],
    "markdown": "## What it is\n\nContainers-as-a-Service (CaaS) is a cloud service that helps manage and deploy apps \nusing [container](https://glossary.cncf.io/container/)-based [abstraction](https://glossary.cncf.io/abstraction/). \nThis service can be deployed on-premises or in the cloud. \n\nCaaS providers offer a framework or orchestration platform that \nautomates key IT functions on which containers are deployed and managed. \nIt helps developers build secure and [scalable](https://glossary.cncf.io/scalability/) containerized apps. \nBecause users only buy the resources they need (scheduling capabilities, load balancing, etc.), \nthey save money and increase efficiency. \nContainers create consistent environments to rapidly develop and \ndeliver [cloud-native applications](https://glossary.cncf.io/cloud-native-apps/) that can run anywhere. \n\n## Problem it addresses\n\nWithout CaaS, software development teams need to deploy, manage, and monitor \nthe underlying infrastructure that containers run on. \n\n## How it helps\n\nWhen deploying containerized applications to a CaaS platform, \nusers gain visibility into system performance through log aggregation and monitoring tools. \nCaaS also includes built-in functionality for [auto scaling](https://glossary.cncf.io/auto-scaling/) and orchestration management. \nIt enables teams to build high visibility and high availability [distributed systems](https://glossary.cncf.io/distributed-systems/). \nIn addition, by allowing rapid deployments, CaaS increases team development velocity. \nWhile containers ensure a consistent deployment target, \nCaaS lowers engineering operating costs \nby reducing needed [DevOps](https://glossary.cncf.io/devops/) resources needed to manage a deployment.\n",
    "what_it_is": "Containers-as-a-Service (CaaS) is a cloud service that helps manage and deploy apps \nusing [container](https://glossary.cncf.io/container/)-based [abstraction](https://glossary.cncf.io/abstraction/). \nThis service can be deployed on-premises or in the cloud. \n\nCaaS providers offer a framework or orchestration platform that \nautomates key IT functions on which containers are deployed and managed. \nIt helps developers build secure and [scalable](https://glossary.cncf.io/scalability/) containerized apps. \nBecause users only buy the resources they need (scheduling capabilities, load balancing, etc.), \nthey save money and increase efficiency. \nContainers create consistent environments to rapidly develop and \ndeliver [cloud-native applications](https://glossary.cncf.io/cloud-native-apps/) that can run anywhere.",
    "problem_it_addresses": "Without CaaS, software development teams need to deploy, manage, and monitor \nthe underlying infrastructure that containers run on.",
    "how_it_helps": "When deploying containerized applications to a CaaS platform, \nusers gain visibility into system performance through log aggregation and monitoring tools. \nCaaS also includes built-in functionality for [auto scaling](https://glossary.cncf.io/auto-scaling/) and orchestration management. \nIt enables teams to build high visibility and high availability [distributed systems](https://glossary.cncf.io/distributed-systems/). \nIn addition, by allowing rapid deployments, CaaS increases team development velocity. \nWhile containers ensure a consistent deployment target, \nCaaS lowers engineering operating costs \nby reducing needed [DevOps](https://glossary.cncf.io/devops/) resources needed to manage a deployment.",
    "slug": "containers-as-a-service"
  },
  {
    "url": "https://glossary.cncf.io/containerization",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/containerization.md",
    "title": "Containerization",
    "status": "Completed",
    "category": "Technology",
    "tags": [
      "application"
    ],
    "markdown": "## What it is\n\nContainerization is the process of bundling an application and its dependencies into a [container image](https://glossary.cncf.io/container-image/). \nThe container build process requires adherence to the [Open Container Initiative](https://opencontainers.org/) (OCI) standard. \nAs long as the output is a container image that adheres to this standard, which containerization tool is used doesn't matter.\n\n## Problem it addresses \n\nBefore containers became prevalent, organizations relied on virtual machines (VMs) to \norchestrate multiple applications on a single [bare-metal machine](https://glossary.cncf.io/bare-metal-machine/). \nVMs are significantly larger than containers and require a hypervisor to run. \nDue to the storage, backup, and transfer of these larger VM templates, creating the VM templates is also slow. \nAdditionally, VMs can suffer from configuration drift which violates the principle of [immutability](https://glossary.cncf.io/immutable-infrastructure/).\n\n## How it helps\n\nContainer images are lightweight (unlike traditional VMs) and \nthe containerization process requires a file with a list of dependencies. \nThis file can be version controlled and the build process automated, \nallowing an organization to focus on other priorities \nwhile the automated processes take care of the build. \nA container image is stored by a unique identifier \nthat is tied to its exact content and configuration. \nAs containers are scheduled and rescheduled, \nthey are always reset to their initial state which eliminates configuration drift.\n",
    "what_it_is": "Containerization is the process of bundling an application and its dependencies into a [container image](https://glossary.cncf.io/container-image/). \nThe container build process requires adherence to the [Open Container Initiative](https://opencontainers.org/) (OCI) standard. \nAs long as the output is a container image that adheres to this standard, which containerization tool is used doesn't matter.",
    "problem_it_addresses": "Before containers became prevalent, organizations relied on virtual machines (VMs) to \norchestrate multiple applications on a single [bare-metal machine](https://glossary.cncf.io/bare-metal-machine/). \nVMs are significantly larger than containers and require a hypervisor to run. \nDue to the storage, backup, and transfer of these larger VM templates, creating the VM templates is also slow. \nAdditionally, VMs can suffer from configuration drift which violates the principle of [immutability](https://glossary.cncf.io/immutable-infrastructure/).",
    "how_it_helps": "Container images are lightweight (unlike traditional VMs) and \nthe containerization process requires a file with a list of dependencies. \nThis file can be version controlled and the build process automated, \nallowing an organization to focus on other priorities \nwhile the automated processes take care of the build. \nA container image is stored by a unique identifier \nthat is tied to its exact content and configuration. \nAs containers are scheduled and rescheduled, \nthey are always reset to their initial state which eliminates configuration drift.",
    "slug": "containerization"
  },
  {
    "url": "https://glossary.cncf.io/container",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/container.md",
    "title": "Containers",
    "status": "Completed",
    "category": "technology",
    "tags": [
      "application",
      "fundamental"
    ],
    "markdown": "## What it is\n\nA container is a running process with resource and capability constraints managed by a computer’s operating system. \nThe files available to the container process are packaged as a container image. \nContainers run adjacent to each other on the same machine, \nbut typically the operating system prevents the separate container processes from interacting with each other.\n\n## Problem it addresses\n\nBefore containers were available, separate machines were necessary to run applications. \nEach machine would require its own operating system, which takes CPU, memory, and disk space, \nall for an individual application to function. \nAdditionally, the maintenance, upgrade, and startup of an operating system is another significant source of toil. \n\n## How it helps\n\nContainers share the same operating system and its machine resources, \nspreading the operating system’s resource overhead and creating efficient use of the physical machine. \nThis capability is only possible because containers are typically limited from being able to interact with each other. \nThis allows many more applications to be run on the same physical machine.\n\nThere are limitations, however. \nSince containers share the same operating system, processes can be considered less secure than alternatives. \nContainers also require limits on the shared resources. \nTo guarantee resources, administrators must constrain and limit memory and CPU usage so that other applications do not perform poorly.\n",
    "what_it_is": "A container is a running process with resource and capability constraints managed by a computer’s operating system. \nThe files available to the container process are packaged as a container image. \nContainers run adjacent to each other on the same machine, \nbut typically the operating system prevents the separate container processes from interacting with each other.",
    "problem_it_addresses": "Before containers were available, separate machines were necessary to run applications. \nEach machine would require its own operating system, which takes CPU, memory, and disk space, \nall for an individual application to function. \nAdditionally, the maintenance, upgrade, and startup of an operating system is another significant source of toil.",
    "how_it_helps": "Containers share the same operating system and its machine resources, \nspreading the operating system’s resource overhead and creating efficient use of the physical machine. \nThis capability is only possible because containers are typically limited from being able to interact with each other. \nThis allows many more applications to be run on the same physical machine.\n\nThere are limitations, however. \nSince containers share the same operating system, processes can be considered less secure than alternatives. \nContainers also require limits on the shared resources. \nTo guarantee resources, administrators must constrain and limit memory and CPU usage so that other applications do not perform poorly.",
    "slug": "container"
  },
  {
    "url": "https://glossary.cncf.io/container-orchestration",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/container-orchestration.md",
    "title": "Container Orchestration",
    "status": "Completed",
    "category": "Concept",
    "markdown": "## What it is\n[Container](https://glossary.cncf.io/container/) orchestration refers to managing and automating the lifecycle of containerized applications in dynamic environments. \nIt's executed through a container orchestrator (in most cases, [Kubernetes](https://glossary.cncf.io/kubernetes)), which enables deployments, (auto)scaling, auto-healing, and monitoring. \nOrchestration is a metaphor:\nThe orchestration tool conducts containers like a music conductor, ensuring every container (or musician) does what it should. \n\n## Problem it addresses \nManaging [microservices](https://glossary.cncf.io/microservices), security, and network communication at scale — and [distributed systems](https://glossary.cncf.io/distributed-systems) in general — is hard, if not impossible, to manage manually.\nContainer orchestration allows users to automate all these management tasks. \n\n## How it helps\nContainer orchestration tools allow users to determine a system's state. \nFirst, they declare how it should look like (e.g., x containers, y pods, etc.).\nThe orchestration tool will then automatically monitor the infrastructure and correct it if its state deviates from the declared one (e.g., spin up a new container if one crashes). \nThis automation simplifies many of the engineering teams' otherwise highly manual and complex operational tasks, including provisioning, deployment, scaling (up and down), networking, load balancing, and other activities.\n",
    "what_it_is": "[Container](https://glossary.cncf.io/container/) orchestration refers to managing and automating the lifecycle of containerized applications in dynamic environments. \nIt's executed through a container orchestrator (in most cases, [Kubernetes](https://glossary.cncf.io/kubernetes)), which enables deployments, (auto)scaling, auto-healing, and monitoring. \nOrchestration is a metaphor:\nThe orchestration tool conducts containers like a music conductor, ensuring every container (or musician) does what it should.",
    "problem_it_addresses": "Managing [microservices](https://glossary.cncf.io/microservices), security, and network communication at scale — and [distributed systems](https://glossary.cncf.io/distributed-systems) in general — is hard, if not impossible, to manage manually.\nContainer orchestration allows users to automate all these management tasks.",
    "how_it_helps": "Container orchestration tools allow users to determine a system's state. \nFirst, they declare how it should look like (e.g., x containers, y pods, etc.).\nThe orchestration tool will then automatically monitor the infrastructure and correct it if its state deviates from the declared one (e.g., spin up a new container if one crashes). \nThis automation simplifies many of the engineering teams' otherwise highly manual and complex operational tasks, including provisioning, deployment, scaling (up and down), networking, load balancing, and other activities.",
    "slug": "container-orchestration"
  },
  {
    "url": "https://glossary.cncf.io/container-image",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/container-image.md",
    "title": "Container Image",
    "status": "Feedback Appreciated",
    "category": "concept",
    "tags": [],
    "markdown": "## What it is\n\nA container image is an immutable, static file containing the dependencies for the creation of a [container](https://glossary.cncf.io/container/). \nThese dependencies may include a single executable binary file, system libraries, \nsystem tools, environment variables, and other required platform settings. \nContainer images result from an application's [containerization](https://glossary.cncf.io/containerization/) and are typically stored in container registries, \nwhere they can be downloaded and run as an isolated process using a Container Runtime Interface (CRI). \nA container image framework must follow the standard schema defined by the Open Container Initiative (OCI).\n\n## Problem it addresses \n\nTraditionally, application servers are configured per environment, and applications are deployed to them. \nAny misconfiguration between environments is problematic and often leads to downtime or failed deployments. \nAn application's environment needs to be repeatable and well-defined; \notherwise, the chance of environment-related bugs increases. \nWhen application environments are configured inadequately or inaccurate, \n[horizontal](https://glossary.cncf.io/horizontal-scaling/) and [vertical](https://glossary.cncf.io/vertical-scaling/) scaling of applications becomes challenging. \n\n## How it helps\n\nContainer images bundle an application with any of its runtime dependencies, such as an application server. \nThis provides consistency across all environments, including a developer's machine. \nContainer images can be used to instantiate as many containers as needed, allowing for greater [scalability](https://glossary.cncf.io/scalability/). \n",
    "what_it_is": "A container image is an immutable, static file containing the dependencies for the creation of a [container](https://glossary.cncf.io/container/). \nThese dependencies may include a single executable binary file, system libraries, \nsystem tools, environment variables, and other required platform settings. \nContainer images result from an application's [containerization](https://glossary.cncf.io/containerization/) and are typically stored in container registries, \nwhere they can be downloaded and run as an isolated process using a Container Runtime Interface (CRI). \nA container image framework must follow the standard schema defined by the Open Container Initiative (OCI).",
    "problem_it_addresses": "Traditionally, application servers are configured per environment, and applications are deployed to them. \nAny misconfiguration between environments is problematic and often leads to downtime or failed deployments. \nAn application's environment needs to be repeatable and well-defined; \notherwise, the chance of environment-related bugs increases. \nWhen application environments are configured inadequately or inaccurate, \n[horizontal](https://glossary.cncf.io/horizontal-scaling/) and [vertical](https://glossary.cncf.io/vertical-scaling/) scaling of applications becomes challenging.",
    "how_it_helps": "Container images bundle an application with any of its runtime dependencies, such as an application server. \nThis provides consistency across all environments, including a developer's machine. \nContainer images can be used to instantiate as many containers as needed, allowing for greater [scalability](https://glossary.cncf.io/scalability/).",
    "slug": "container-image"
  },
  {
    "url": "https://glossary.cncf.io/cluster",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/cluster.md",
    "title": "Cluster",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "infrastructure",
      "fundamental"
    ],
    "markdown": "## What it is\n\nA cluster is a group of computers or applications that work together towards a common goal. \nIn the context of cloud native computing, the term is most often applied to [Kubernetes](https://glossary.cncf.io/kubernetes/). \nA Kubernetes cluster is a set of services (or workloads) that run in their own containers, usually on different machines. \nThe collection of all these [containerized](https://glossary.cncf.io/containerization/) services, connected over a network, represent a cluster.\n\n## Problem it addresses \n\nSoftware that runs on a single computer presents a single point of failure \n— if that computer crashes, or someone accidentally unplugs the power cable, \nthen some business-critical system may be taken offline. \nThat's why modern software is generally built as [distributed applications](https://glossary.cncf.io/distributed-apps/), grouped together as clusters. \n\n## How it helps\n\nClustered, distributed applications run across multiple machines, eliminating a single point of failure. \nBut building distributed systems is really hard. \nIn fact, it's a computer science discipline in its own right. \nThe need for global systems and years of trial and error led to the development of a new kind of tech stack: \n[cloud native technologies](https://glossary.cncf.io/cloud-native-tech/). \nThese new technologies are the building blocks that make the operation and creation of distributed systems easier.\n",
    "what_it_is": "A cluster is a group of computers or applications that work together towards a common goal. \nIn the context of cloud native computing, the term is most often applied to [Kubernetes](https://glossary.cncf.io/kubernetes/). \nA Kubernetes cluster is a set of services (or workloads) that run in their own containers, usually on different machines. \nThe collection of all these [containerized](https://glossary.cncf.io/containerization/) services, connected over a network, represent a cluster.",
    "problem_it_addresses": "Software that runs on a single computer presents a single point of failure \n— if that computer crashes, or someone accidentally unplugs the power cable, \nthen some business-critical system may be taken offline. \nThat's why modern software is generally built as [distributed applications](https://glossary.cncf.io/distributed-apps/), grouped together as clusters.",
    "how_it_helps": "Clustered, distributed applications run across multiple machines, eliminating a single point of failure. \nBut building distributed systems is really hard. \nIn fact, it's a computer science discipline in its own right. \nThe need for global systems and years of trial and error led to the development of a new kind of tech stack: \n[cloud native technologies](https://glossary.cncf.io/cloud-native-tech/). \nThese new technologies are the building blocks that make the operation and creation of distributed systems easier.",
    "slug": "cluster"
  },
  {
    "url": "https://glossary.cncf.io/cloud-native-tech",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/cloud-native-tech.md",
    "title": "Cloud Native Technology",
    "status": "Completed",
    "category": "Concept",
    "tags": [
      "fundamental"
    ],
    "markdown": "## What it is\n\nCloud native technologies, also referred to as the cloud native stack, \nare the technologies used to build [cloud native applications](https://glossary.cncf.io/cloud-native-apps/). \nThese technologies enable organizations to build and run scalable applications in modern and dynamic environments \nsuch as public, private, and hybrid clouds, \nwhile leveraging [cloud computing](https://glossary.cncf.io/cloud-computing/) benefits to their fullest. \nThey are designed from the ground up to exploit the capabilities of cloud computing and containers, service meshes, microservices, \nand immutable infrastructure exemplify this approach.\n\n## Problem it addresses \n\nThe cloud native stack has many different technology categories, addressing a variety of challenges. \nIf you have a look at the [CNCF Cloud Native Landscape](https://landscape.cncf.io/), \nyou'll see how many different areas it touches upon. \nBut on a high level, they address one main set of challenges: \nthe downsides of traditional IT operating models. \nChallenges include difficulties creating scalable, fault-tolerant, self-healing applications, \nas well as inefficient resource utilization, among others.\n\n## How it helps\n\nWhile each technology addresses a very specific problem, \nas a group, cloud native technologies enable loosely coupled systems that are resilient, manageable, and observable. \nCombined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil. \nDesirable traits of cloud native systems are easier to achieve with the cloud native stack.\n",
    "what_it_is": "Cloud native technologies, also referred to as the cloud native stack, \nare the technologies used to build [cloud native applications](https://glossary.cncf.io/cloud-native-apps/). \nThese technologies enable organizations to build and run scalable applications in modern and dynamic environments \nsuch as public, private, and hybrid clouds, \nwhile leveraging [cloud computing](https://glossary.cncf.io/cloud-computing/) benefits to their fullest. \nThey are designed from the ground up to exploit the capabilities of cloud computing and containers, service meshes, microservices, \nand immutable infrastructure exemplify this approach.",
    "problem_it_addresses": "The cloud native stack has many different technology categories, addressing a variety of challenges. \nIf you have a look at the [CNCF Cloud Native Landscape](https://landscape.cncf.io/), \nyou'll see how many different areas it touches upon. \nBut on a high level, they address one main set of challenges: \nthe downsides of traditional IT operating models. \nChallenges include difficulties creating scalable, fault-tolerant, self-healing applications, \nas well as inefficient resource utilization, among others.",
    "how_it_helps": "While each technology addresses a very specific problem, \nas a group, cloud native technologies enable loosely coupled systems that are resilient, manageable, and observable. \nCombined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil. \nDesirable traits of cloud native systems are easier to achieve with the cloud native stack.",
    "slug": "cloud-native-tech"
  },
  {
    "url": "https://glossary.cncf.io/cloud-native-security",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/cloud-native-security.md",
    "title": "Cloud Native Security",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "security"
    ],
    "markdown": "## What it is\n\nCloud native security is an approach that builds security into [cloud native applications](https://glossary.cncf.io/cloud-native-apps/). \nIt ensures that security is part of the entire application lifecycle from development to production. \nCloud native security seeks to ensure the same standards as traditional security models \nwhile adapting to the particulars of cloud native environments, \nnamely rapid code changes and highly ephemeral infrastructure. \nCloud native security is highly related to the practice called [DevSecOps](https://glossary.cncf.io/devsecops/).\n\n## Problem it addresses\n\nTraditional security models were built with a number of assumptions that are no longer valid. \nCloud native apps change frequently, use a large number of open source tools and libraries, \noften run in vendor-controlled infrastructure, and are subject to rapid infrastructure changes. \nCode reviews, long quality assurance cycles, host-based vulnerability scanning, \nand last minute security reviews cannot scale with cloud native applications.\n\n## How it helps\n\nCloud native security introduces a new way of working that protects applications \nby migrating from traditional security models to one where security is involved in every step of the release cycle. \nManual audits and checks are largely replaced with automated scans. \nRapid code release pipelines are integrated with tools that scan code for vulnerabilities before they’re compiled. \nOpen source libraries are pulled from trusted sources and monitored for vulnerabilities. \nInstead of slowing change a cloud native security model embraces it \nby frequently updated vulnerable components or ensuring infrastructure is regularly replaced.\n",
    "what_it_is": "Cloud native security is an approach that builds security into [cloud native applications](https://glossary.cncf.io/cloud-native-apps/). \nIt ensures that security is part of the entire application lifecycle from development to production. \nCloud native security seeks to ensure the same standards as traditional security models \nwhile adapting to the particulars of cloud native environments, \nnamely rapid code changes and highly ephemeral infrastructure. \nCloud native security is highly related to the practice called [DevSecOps](https://glossary.cncf.io/devsecops/).",
    "problem_it_addresses": "Traditional security models were built with a number of assumptions that are no longer valid. \nCloud native apps change frequently, use a large number of open source tools and libraries, \noften run in vendor-controlled infrastructure, and are subject to rapid infrastructure changes. \nCode reviews, long quality assurance cycles, host-based vulnerability scanning, \nand last minute security reviews cannot scale with cloud native applications.",
    "how_it_helps": "Cloud native security introduces a new way of working that protects applications \nby migrating from traditional security models to one where security is involved in every step of the release cycle. \nManual audits and checks are largely replaced with automated scans. \nRapid code release pipelines are integrated with tools that scan code for vulnerabilities before they’re compiled. \nOpen source libraries are pulled from trusted sources and monitored for vulnerabilities. \nInstead of slowing change a cloud native security model embraces it \nby frequently updated vulnerable components or ensuring infrastructure is regularly replaced.",
    "slug": "cloud-native-security"
  },
  {
    "url": "https://glossary.cncf.io/cloud-native-apps",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/cloud-native-apps.md",
    "title": "Cloud Native Apps",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "application",
      "fundamental"
    ],
    "markdown": "## What it is\n\nCloud native applications are specifically designed to take advantage of innovations in [cloud computing](https://glossary.cncf.io/cloud-computing/). \nThese applications integrate easily with their respective cloud architectures, \ntaking advantage of the cloud’s resources and [scaling](https://glossary.cncf.io/scalability/) capabilities. \nIt also refers to applications that take advantage of innovations in infrastructure driven by cloud computing. \nCloud native applications today include apps that run in a cloud provider’s datacenter and on cloud native platforms on-premise.\n\n## Problem it addresses\n\nTraditionally, on-premise environments provided compute resources in a fairly bespoke way. \nEach datacenter had services that [tightly coupled](https://glossary.cncf.io/tightly-coupled-architectures/) applications to specific environments, \noften relying heavily on manual provisioning for infrastructure, like [virtual machines](https://glossary.cncf.io/virtual-machine/) and services. \nThis, in turn, constrained developers and their applications to that specific datacenter. \nApplications that weren't designed for the cloud couldn't take advantage of a cloud environment’s resiliency and scaling capabilities. \nFor example, apps that require manual intervention to start correctly cannot scale automatically, \nnor can they be automatically restarted in the event of a failure.  \n\n## How it helps\n\nWhile there is no “one size fits all” path to cloud native applications, they do have some commonalities. \nCloud native apps are resilient, manageable, and aided by the suite of cloud services that accompany them. \nThe various cloud services enable a high degree of [observability](https://glossary.cncf.io/observability/), \nenabling users to detect and address issues before they escalate. \nCombined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.\n",
    "what_it_is": "Cloud native applications are specifically designed to take advantage of innovations in [cloud computing](https://glossary.cncf.io/cloud-computing/). \nThese applications integrate easily with their respective cloud architectures, \ntaking advantage of the cloud’s resources and [scaling](https://glossary.cncf.io/scalability/) capabilities. \nIt also refers to applications that take advantage of innovations in infrastructure driven by cloud computing. \nCloud native applications today include apps that run in a cloud provider’s datacenter and on cloud native platforms on-premise.",
    "problem_it_addresses": "Traditionally, on-premise environments provided compute resources in a fairly bespoke way. \nEach datacenter had services that [tightly coupled](https://glossary.cncf.io/tightly-coupled-architectures/) applications to specific environments, \noften relying heavily on manual provisioning for infrastructure, like [virtual machines](https://glossary.cncf.io/virtual-machine/) and services. \nThis, in turn, constrained developers and their applications to that specific datacenter. \nApplications that weren't designed for the cloud couldn't take advantage of a cloud environment’s resiliency and scaling capabilities. \nFor example, apps that require manual intervention to start correctly cannot scale automatically, \nnor can they be automatically restarted in the event of a failure.",
    "how_it_helps": "While there is no “one size fits all” path to cloud native applications, they do have some commonalities. \nCloud native apps are resilient, manageable, and aided by the suite of cloud services that accompany them. \nThe various cloud services enable a high degree of [observability](https://glossary.cncf.io/observability/), \nenabling users to detect and address issues before they escalate. \nCombined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.",
    "slug": "cloud-native-apps"
  },
  {
    "url": "https://glossary.cncf.io/cloud-computing",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/cloud-computing.md",
    "title": "Cloud Computing",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "infrastructure",
      "fundamental"
    ],
    "markdown": "## What it is\n\nCloud computing is a model that offers compute resources like CPU, network, and disk capabilities on-demand over the internet. \nCloud computing gives users the ability to access and use computing power in a remote physical location. \nCloud providers like AWS, GCP, Azure, DigitalOcean, and others all offer third parties \nthe ability to rent access to compute resources in multiple geographic locations.\n\n## Problem it addresses\n\nOrganizations traditionally faced two main problems when attempting to expand their use of computing power. \nThey either acquire, support, design, and pay for facilities \nto host their physical servers and network or expand and maintain those facilities. \nCloud computing allows organizations to outsource some portion of their computing needs to another organization.\n\n## How it helps\n\nCloud providers offer organizations the ability to rent compute resources on-demand and pay for usage. \nThis allows for two major innovations: \nOrganizations can focus on their product or service without waiting, planning, and spending resources on new physical infrastructure. They can simply [scale](https://glossary.cncf.io/scalability/) as needed and on-demand.\nCloud computing allows organizations to adopt as much or as little infrastructure as they need.\n",
    "what_it_is": "Cloud computing is a model that offers compute resources like CPU, network, and disk capabilities on-demand over the internet. \nCloud computing gives users the ability to access and use computing power in a remote physical location. \nCloud providers like AWS, GCP, Azure, DigitalOcean, and others all offer third parties \nthe ability to rent access to compute resources in multiple geographic locations.",
    "problem_it_addresses": "Organizations traditionally faced two main problems when attempting to expand their use of computing power. \nThey either acquire, support, design, and pay for facilities \nto host their physical servers and network or expand and maintain those facilities. \nCloud computing allows organizations to outsource some portion of their computing needs to another organization.",
    "how_it_helps": "Cloud providers offer organizations the ability to rent compute resources on-demand and pay for usage. \nThis allows for two major innovations: \nOrganizations can focus on their product or service without waiting, planning, and spending resources on new physical infrastructure. They can simply [scale](https://glossary.cncf.io/scalability/) as needed and on-demand.\nCloud computing allows organizations to adopt as much or as little infrastructure as they need.",
    "slug": "cloud-computing"
  },
  {
    "url": "https://glossary.cncf.io/client-server-architecture",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/client-server-architecture.md",
    "title": "Client-Server Architecture",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "architecture",
      "fundamental"
    ],
    "markdown": "## What it is\n\nIn a client-server architecture, the logic (or code) that makes up an application is split between two or more components: \na client that asks for work to be done \n(e.g. the Gmail web application running in your web browser), \nand one or more servers that satisfy that request \n(e.g. the \"send email\" service running on Google’s computers in the cloud). \nIn this example, outgoing emails that you write are sent by the client (web application running in your web browser) \nto a server (Gmail's computers, which forward your outgoing emails to their recipients).\n\nThis contrasts with self-contained applications (such as desktop applications) that do all the work in one place. \nFor example, a word processing program like Microsoft Word may be installed and run entirely on your computer.\n\n## Problem it addresses \n\nA client-server architecture solves a big challenge self-contained applications pose: regular updates. \nIn a self-contained app, for each update, users would have to download and install the latest version. \nImagine having to download all of Amazon’s product catalog to your own computer before being able to browse it!\n\n## How it helps\n\nBy implementing application logic in a remote server or service, \noperators can update that without needing to change the logic on the client-side. \nThis means updates can be made much more frequently. \nStoring data on the server allows many clients to all see and share the same data. \nConsider the difference between using an online word processor, compared to a traditional offline word processor. \nIn the former, your files exist on the server-side and \ncan be shared with other users who simply download them from the server. \nIn the legacy world, files needed to be copied to removable media (floppy disks!) and shared with individuals.\n",
    "what_it_is": "In a client-server architecture, the logic (or code) that makes up an application is split between two or more components: \na client that asks for work to be done \n(e.g. the Gmail web application running in your web browser), \nand one or more servers that satisfy that request \n(e.g. the \"send email\" service running on Google’s computers in the cloud). \nIn this example, outgoing emails that you write are sent by the client (web application running in your web browser) \nto a server (Gmail's computers, which forward your outgoing emails to their recipients).\n\nThis contrasts with self-contained applications (such as desktop applications) that do all the work in one place. \nFor example, a word processing program like Microsoft Word may be installed and run entirely on your computer.",
    "problem_it_addresses": "A client-server architecture solves a big challenge self-contained applications pose: regular updates. \nIn a self-contained app, for each update, users would have to download and install the latest version. \nImagine having to download all of Amazon’s product catalog to your own computer before being able to browse it!",
    "how_it_helps": "By implementing application logic in a remote server or service, \noperators can update that without needing to change the logic on the client-side. \nThis means updates can be made much more frequently. \nStoring data on the server allows many clients to all see and share the same data. \nConsider the difference between using an online word processor, compared to a traditional offline word processor. \nIn the former, your files exist on the server-side and \ncan be shared with other users who simply download them from the server. \nIn the legacy world, files needed to be copied to removable media (floppy disks!) and shared with individuals.",
    "slug": "client-server-architecture"
  },
  {
    "url": "https://glossary.cncf.io/chaos-engineering",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/chaos-engineering.md",
    "title": "Chaos Engineering",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology"
    ],
    "markdown": "## What it is\n\nChaos Engineering or CE is the discipline of experimenting on a [distributed system](https://glossary.cncf.io/distributed-systems/) in production \nto build confidence in the system's capability to withstand turbulent and unexpected conditions.\n\n## Problem it addresses\n\n[SRE](https://glossary.cncf.io/site-reliability-engineering/) and [DevOps](https://glossary.cncf.io/devops/) practices focus on \ntechniques to increase product resiliency and [reliability](https://glossary.cncf.io/reliability/). \nA system's ability to tolerate failures while ensuring adequate service quality is \ntypically a software development requirement. \nThere are several aspects involved that could lead to outages of an application, \nlike infrastructure, platform or other moving parts of a ([microservice](https://glossary.cncf.io/microservices/)-based) application. \nHigh-frequency deployment of new features to the production environment can \nresult in a high probability of downtime and a critical incident \n— with considerable consequences to the business.\n\n## How it helps\n\nChaos engineering is a technique to meet resilience requirements. \nIt is used to achieve resilience against infrastructure, platform, and application failures. \nChaos engineers use chaos experiments to proactively inject random failures \nto verify that an application, infrastructure, or platform can self-heal and the failure cannot noticeably impact customers. \nChaos experiments aim to discover blind spots \n(e.g. monitoring or autoscaling techniques) and to improve the communications between teams during critical incidents. \nThis approach helps increase resiliency and the team's confidence in complex systems, particularly production.\n",
    "what_it_is": "Chaos Engineering or CE is the discipline of experimenting on a [distributed system](https://glossary.cncf.io/distributed-systems/) in production \nto build confidence in the system's capability to withstand turbulent and unexpected conditions.",
    "problem_it_addresses": "[SRE](https://glossary.cncf.io/site-reliability-engineering/) and [DevOps](https://glossary.cncf.io/devops/) practices focus on \ntechniques to increase product resiliency and [reliability](https://glossary.cncf.io/reliability/). \nA system's ability to tolerate failures while ensuring adequate service quality is \ntypically a software development requirement. \nThere are several aspects involved that could lead to outages of an application, \nlike infrastructure, platform or other moving parts of a ([microservice](https://glossary.cncf.io/microservices/)-based) application. \nHigh-frequency deployment of new features to the production environment can \nresult in a high probability of downtime and a critical incident \n— with considerable consequences to the business.",
    "how_it_helps": "Chaos engineering is a technique to meet resilience requirements. \nIt is used to achieve resilience against infrastructure, platform, and application failures. \nChaos engineers use chaos experiments to proactively inject random failures \nto verify that an application, infrastructure, or platform can self-heal and the failure cannot noticeably impact customers. \nChaos experiments aim to discover blind spots \n(e.g. monitoring or autoscaling techniques) and to improve the communications between teams during critical incidents. \nThis approach helps increase resiliency and the team's confidence in complex systems, particularly production.",
    "slug": "chaos-engineering"
  },
  {
    "url": "https://glossary.cncf.io/canary-deployment",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/canary-deployment.md",
    "title": "Canary Deployment",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology",
      "application"
    ],
    "markdown": "## What it is\n\nCanary deployments is a deployment strategy that starts with two environments: \none with live traffic and the other containing the updated code without live traffic. \nThe traffic is gradually moved from the original version of the application to the updated version. \nIt can start by moving 1% of live traffic, then 10%, 25%, and so on, \nuntil all traffic is running through the updated version. \nOrganizations can test the new version of the software in production, get feedback, \ndiagnose errors, and quickly rollback to the stable version if necessary.  \n\nThe term “canary” refers to the \"canary in a coal mine\" practice \nwhere canary birds were taken into coal mines to keep miners safe. \nIf odorless harmful gases were present, the bird would die, and the miners knew they had to evacuate quickly. \nSimilarly, if something goes wrong with the updated code, live traffic is \"evacuated\" back to the original version. \n\n## Problem it addresses\n\nNo matter how thorough the testing strategy, there are always some bugs discovered in production. \nShifting 100% of traffic from one version of an app to another can lead to more impactful failures.\n\n## How it helps\n\nCanary deployments allow organizations to see how new software behaves in real-world scenarios \nbefore moving significant traffic to the new version. \nThis strategy enables organizations to minimize downtime and quickly rollback in case of issues with the new deployment. \nIt also allows more in-depth production application testing without a significant impact on the overall user experience.\n",
    "what_it_is": "Canary deployments is a deployment strategy that starts with two environments: \none with live traffic and the other containing the updated code without live traffic. \nThe traffic is gradually moved from the original version of the application to the updated version. \nIt can start by moving 1% of live traffic, then 10%, 25%, and so on, \nuntil all traffic is running through the updated version. \nOrganizations can test the new version of the software in production, get feedback, \ndiagnose errors, and quickly rollback to the stable version if necessary.  \n\nThe term “canary” refers to the \"canary in a coal mine\" practice \nwhere canary birds were taken into coal mines to keep miners safe. \nIf odorless harmful gases were present, the bird would die, and the miners knew they had to evacuate quickly. \nSimilarly, if something goes wrong with the updated code, live traffic is \"evacuated\" back to the original version.",
    "problem_it_addresses": "No matter how thorough the testing strategy, there are always some bugs discovered in production. \nShifting 100% of traffic from one version of an app to another can lead to more impactful failures.",
    "how_it_helps": "Canary deployments allow organizations to see how new software behaves in real-world scenarios \nbefore moving significant traffic to the new version. \nThis strategy enables organizations to minimize downtime and quickly rollback in case of issues with the new deployment. \nIt also allows more in-depth production application testing without a significant impact on the overall user experience.",
    "slug": "canary-deployment"
  },
  {
    "url": "https://glossary.cncf.io/blue-green-deployment",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/blue-green-deployment.md",
    "title": "Blue Green Deployment",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology",
      "application"
    ],
    "markdown": "## What it is\n\nBlue-green deployment is a strategy for updating running computer systems with minimal downtime. \nThe operator maintains two environments, dubbed “blue” and “green”. \nOne serves production traffic (the version all users are currently using), whilst the other is updated. \nOnce testing has concluded on the non-active (green) environment, \nproduction traffic is switched over (often via the use of a [load balancer](https://glossary.cncf.io/load-balancer/)). \nNote that blue-green deployment usually means switching the entire environments, comprising many [services](https://glossary.cncf.io/service/), all at once. \nConfusingly, sometimes the term is used with regard to individual services within a system. \nTo avoid this ambiguity, the term “zero-downtime deployment” is preferred when referring to individual components.\n\n## Problem it addresses\n\nBlue-green deployments allow minimal downtime when updating software that must be changed in \"lockstep\" owing to a lack of backwards compatibility. \nFor example, blue-green deployment would be appropriate for an online store \nconsisting of a website and a database that needs to be updated, \nbut the new version of the database doesn’t work with the old version of the website, and vice versa. \nIn this instance, both need to be changed at the same time. \nIf this was done on the production system, customers would notice downtime.\n\n## How it helps\n\nBlue-green deployment is an appropriate strategy for non-cloud native software that needs to be updated with minimal downtime. \nHowever, its use is normally a \"smell\" that legacy software needs to be re-engineered so that components can be updated individually.\n",
    "what_it_is": "Blue-green deployment is a strategy for updating running computer systems with minimal downtime. \nThe operator maintains two environments, dubbed “blue” and “green”. \nOne serves production traffic (the version all users are currently using), whilst the other is updated. \nOnce testing has concluded on the non-active (green) environment, \nproduction traffic is switched over (often via the use of a [load balancer](https://glossary.cncf.io/load-balancer/)). \nNote that blue-green deployment usually means switching the entire environments, comprising many [services](https://glossary.cncf.io/service/), all at once. \nConfusingly, sometimes the term is used with regard to individual services within a system. \nTo avoid this ambiguity, the term “zero-downtime deployment” is preferred when referring to individual components.",
    "problem_it_addresses": "Blue-green deployments allow minimal downtime when updating software that must be changed in \"lockstep\" owing to a lack of backwards compatibility. \nFor example, blue-green deployment would be appropriate for an online store \nconsisting of a website and a database that needs to be updated, \nbut the new version of the database doesn’t work with the old version of the website, and vice versa. \nIn this instance, both need to be changed at the same time. \nIf this was done on the production system, customers would notice downtime.",
    "how_it_helps": "Blue-green deployment is an appropriate strategy for non-cloud native software that needs to be updated with minimal downtime. \nHowever, its use is normally a \"smell\" that legacy software needs to be re-engineered so that components can be updated individually.",
    "slug": "blue-green-deployment"
  },
  {
    "url": "https://glossary.cncf.io/bare-metal-machine",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/bare-metal-machine.md",
    "title": "Bare Metal Machine",
    "status": "Completed",
    "category": "technology",
    "tags": [
      "infrastructure"
    ],
    "markdown": "## What it is\n\nBare metal refers to a physical computer, more specifically a server, that has one, and only one, operating system. \nThe distinction is important in modern computing because many, if not most, servers are [virtual machines](https://glossary.cncf.io/virtual-machine/). \nA physical server is typically a fairly large computer with powerful hardware built-in. \nInstalling an operating system and running applications directly on that physical hardware, \nwithout [virtualization](https://glossary.cncf.io/virtualization/), is referred to as running on “bare metal.”\n\n## Problem it addresses\n\nPairing one operating system with one physical computer is the original pattern of computing. \nAll the resources of the physical computer are available directly to the operating system and with no virtualization layer present, \nthere is no artificial delay in translating operating system instructions to hardware.\n\n## How it helps\n\nBy dedicating all compute resources of a computer to a single operating system, \nyou potentially provide the best possible performance to the operating system. \nIf you need to run a workload that must have extremely fast access to hardware resources, \nbare metal may be the right solution. \n\nIn the context of [cloud native apps](https://glossary.cncf.io/cloud-native-apps/), \nwe generally think of performance in terms of [scaling](https://glossary.cncf.io/scalability/) to a large number of concurrent events, \nwhich can be handled by [horizontal scaling](https://glossary.cncf.io/horizontal-scaling/) (adding more machines to your resource pool). \nBut some workloads may require [vertical scaling](https://glossary.cncf.io/vertical-scaling/) (adding more power to an existing physical machine) \nand/or an extremely fast physical hardware response in which case bare metal is better suited. \nBare metal also allows you to tune the physical hardware and possibly even hardware drivers to help accomplish your task.\n",
    "what_it_is": "Bare metal refers to a physical computer, more specifically a server, that has one, and only one, operating system. \nThe distinction is important in modern computing because many, if not most, servers are [virtual machines](https://glossary.cncf.io/virtual-machine/). \nA physical server is typically a fairly large computer with powerful hardware built-in. \nInstalling an operating system and running applications directly on that physical hardware, \nwithout [virtualization](https://glossary.cncf.io/virtualization/), is referred to as running on “bare metal.”",
    "problem_it_addresses": "Pairing one operating system with one physical computer is the original pattern of computing. \nAll the resources of the physical computer are available directly to the operating system and with no virtualization layer present, \nthere is no artificial delay in translating operating system instructions to hardware.",
    "how_it_helps": "By dedicating all compute resources of a computer to a single operating system, \nyou potentially provide the best possible performance to the operating system. \nIf you need to run a workload that must have extremely fast access to hardware resources, \nbare metal may be the right solution. \n\nIn the context of [cloud native apps](https://glossary.cncf.io/cloud-native-apps/), \nwe generally think of performance in terms of [scaling](https://glossary.cncf.io/scalability/) to a large number of concurrent events, \nwhich can be handled by [horizontal scaling](https://glossary.cncf.io/horizontal-scaling/) (adding more machines to your resource pool). \nBut some workloads may require [vertical scaling](https://glossary.cncf.io/vertical-scaling/) (adding more power to an existing physical machine) \nand/or an extremely fast physical hardware response in which case bare metal is better suited. \nBare metal also allows you to tune the physical hardware and possibly even hardware drivers to help accomplish your task.",
    "slug": "bare-metal-machine"
  },
  {
    "url": "https://glossary.cncf.io/auto-scaling",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/auto-scaling.md",
    "title": "Autoscaling",
    "status": "Completed",
    "category": "property",
    "tags": [
      "infrastructure"
    ],
    "markdown": "Autoscaling is the ability of a system to [scale](https://glossary.cncf.io/scalability/) automatically, typically, in terms of computing resources. \nWith an autoscaling system, resources are automatically added when needed and can scale to meet fluctuating user demands. \nThe autoscaling process varies and is configurable to scale based on different metrics, such as memory or process time. \nManaged cloud services are typically associated with autoscaling functionality \nas there are more options and implementations available than most on-premise deployments.\n\nPreviously, infrastructure and applications were architected to consider peak system usage. \nThis architecture meant that more resources were underutilized and inelastic to changing consumer demand. \nThe inelasticity meant higher costs to the business and lost business from outages due to overdemand.\n\nBy leveraging the cloud, [virtualizing](https://glossary.cncf.io/virtualization/), and [containerizing](https://glossary.cncf.io/containerization/) applications and their dependencies, \norganizations can build applications that scale according to user demands. \nThey can monitor application demand and automatically scale them, providing an optimal user experience. \nTake the increase in viewership Netflix experiences every Friday evening. \nAutoscaling out means dynamically adding more resources: for example, \nincreasing the number of servers allowing for more video streaming and scaling back once consumption has normalized.\n\n## Related terms\n\n* [Horizontal Scaling](https://glossary.cncf.io/horizontal-scaling/)\n* [Vertical Scaling](https://glossary.cncf.io/vertical-scaling/)\n",
    "related_terms": "* [Horizontal Scaling](https://glossary.cncf.io/horizontal-scaling/)\n* [Vertical Scaling](https://glossary.cncf.io/vertical-scaling/)",
    "slug": "auto-scaling"
  },
  {
    "url": "https://glossary.cncf.io/application-programming-interface",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/application-programming-interface.md",
    "title": "Application Programming Interface (API)",
    "status": "Completed",
    "category": "technology",
    "tags": [
      "architecture",
      "fundamental"
    ],
    "markdown": "## What it is\n\nAn API is a way for computer programs to interact with each other. \nJust as humans interact with a website via a web page, an API allows computer programs to interact with each other. \nUnlike human interactions, APIs have limitations on what can and cannot be asked of them. \nThe limitation on interaction helps to create stable and functional communication between programs.\n\n## Problem it addresses\n\nAs applications become more complex, small code changes can have drastic effects on other functionality. \nApplications need to take a modular approach to their functionality if they can grow and maintain stability simultaneously. \nWithout APIs, there is a lack of a framework for the interaction between applications. \nWithout a shared framework, it is challenging for applications to [scale](https://glossary.cncf.io/scalability/) and integrate.\n\n## How it helps\n\nAPIs allow computer programs or applications to interact and share information in a defined and understandable manner. \nThey are the building blocks for modern applications and they provide developers with a way to integrate applications together. \nWhenever you hear about [microservices](https://glossary.cncf.io/microservices/) working together, you can infer that they interact via an API. \n",
    "what_it_is": "An API is a way for computer programs to interact with each other. \nJust as humans interact with a website via a web page, an API allows computer programs to interact with each other. \nUnlike human interactions, APIs have limitations on what can and cannot be asked of them. \nThe limitation on interaction helps to create stable and functional communication between programs.",
    "problem_it_addresses": "As applications become more complex, small code changes can have drastic effects on other functionality. \nApplications need to take a modular approach to their functionality if they can grow and maintain stability simultaneously. \nWithout APIs, there is a lack of a framework for the interaction between applications. \nWithout a shared framework, it is challenging for applications to [scale](https://glossary.cncf.io/scalability/) and integrate.",
    "how_it_helps": "APIs allow computer programs or applications to interact and share information in a defined and understandable manner. \nThey are the building blocks for modern applications and they provide developers with a way to integrate applications together. \nWhenever you hear about [microservices](https://glossary.cncf.io/microservices/) working together, you can infer that they interact via an API.",
    "slug": "application-programming-interface"
  },
  {
    "url": "https://glossary.cncf.io/api-gateway",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/api-gateway.md",
    "title": "API Gateway",
    "status": "Completed",
    "category": "technology",
    "tags": [
      "networking"
    ],
    "markdown": "## What it is\n\nAn [API](https://glossary.cncf.io/application-programming-interface/) gateway is a tool that \naggregates unique application APIs, making them all available in one place. \nIt allows organizations to move key functions, \nsuch as authentication and authorization or limiting the number of requests between applications, \nto a centrally managed location. \nAn API gateway functions as a common interface to (often external) API consumers. \n\n## Problem it addresses\n\nIf you’re making APIs available to external consumers, \nyou'll want one entry point to manage and control all access. \nAdditionally, if you need to apply functionality on those interactions, \nan API gateway allows you to uniformly apply it to all traffic without requiring any app code changes.\n\n## How it helps\n\nProviding one single access point for various APIs in an application, \nAPI gateways make it easier for organizations to apply cross-cutting business or security logic in a central location. \nThey also allow application consumers to go to a single address for all their needs. \nAn API gateway can simplify operational concerns like security and [observability](https://glossary.cncf.io/observability/) \nby providing a single access point for requests to all web services in a system. \nAs all requests flow through the API gateway, it presents a single place to \nadd functionality like metrics-gathering, rate-limiting, and authorization.\n",
    "what_it_is": "An [API](https://glossary.cncf.io/application-programming-interface/) gateway is a tool that \naggregates unique application APIs, making them all available in one place. \nIt allows organizations to move key functions, \nsuch as authentication and authorization or limiting the number of requests between applications, \nto a centrally managed location. \nAn API gateway functions as a common interface to (often external) API consumers.",
    "problem_it_addresses": "If you’re making APIs available to external consumers, \nyou'll want one entry point to manage and control all access. \nAdditionally, if you need to apply functionality on those interactions, \nan API gateway allows you to uniformly apply it to all traffic without requiring any app code changes.",
    "how_it_helps": "Providing one single access point for various APIs in an application, \nAPI gateways make it easier for organizations to apply cross-cutting business or security logic in a central location. \nThey also allow application consumers to go to a single address for all their needs. \nAn API gateway can simplify operational concerns like security and [observability](https://glossary.cncf.io/observability/) \nby providing a single access point for requests to all web services in a system. \nAs all requests flow through the API gateway, it presents a single place to \nadd functionality like metrics-gathering, rate-limiting, and authorization.",
    "slug": "api-gateway"
  },
  {
    "url": "https://glossary.cncf.io/agile-software-development",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/agile-software-development.md",
    "title": "Agile Software Development",
    "status": "Completed",
    "category": "concept",
    "tags": [
      "methodology"
    ],
    "markdown": "## What it is\n\nA set of practices that emphasize iterative development cycles and self-organizing teams. \nIn contrast to waterfall-like projects where value is generated only at the very end of a project, \nagile software development focuses on a continuous, incremental delivery of value and \nevolutionary improvement of the process itself. \n\n## Problem it addresses\n\nDefining, communicating and understanding requirements for all stakeholders in a software project is very difficult, if not impossible. \nYet, customers want their software projects to be delivered on time, in good quality, on budget and on scope. \nWith its cyclical nature, agile software development enables continuous adaptation of requirements and \nfaster adaptation to all other circumstances as opposed to waterfall-like strategies. \n\n## How it helps\n\nAgile software development contains all the phases of traditional (waterfall-like) strategies, \nlike requirements engineering, planning, implementation, review, testing and delivery. \nThe biggest difference is that the whole time span of a software project is sliced into iterations, which each contain all those phases. \nAfter each iteration, the created value can be reviewed with the customer and requirements can be adjusted towards the end goal. \nAdditionally the development team retrospects on which actions items to take in order to improve the process itself. \n",
    "what_it_is": "A set of practices that emphasize iterative development cycles and self-organizing teams. \nIn contrast to waterfall-like projects where value is generated only at the very end of a project, \nagile software development focuses on a continuous, incremental delivery of value and \nevolutionary improvement of the process itself.",
    "problem_it_addresses": "Defining, communicating and understanding requirements for all stakeholders in a software project is very difficult, if not impossible. \nYet, customers want their software projects to be delivered on time, in good quality, on budget and on scope. \nWith its cyclical nature, agile software development enables continuous adaptation of requirements and \nfaster adaptation to all other circumstances as opposed to waterfall-like strategies.",
    "how_it_helps": "Agile software development contains all the phases of traditional (waterfall-like) strategies, \nlike requirements engineering, planning, implementation, review, testing and delivery. \nThe biggest difference is that the whole time span of a software project is sliced into iterations, which each contain all those phases. \nAfter each iteration, the created value can be reviewed with the customer and requirements can be adjusted towards the end goal. \nAdditionally the development team retrospects on which actions items to take in order to improve the process itself.",
    "slug": "agile-software-development"
  },
  {
    "url": "https://glossary.cncf.io/abstraction",
    "srcUrl": "https://github.com/cncf/glossary/blob/main/content/en/abstraction.md",
    "title": "Abstraction",
    "status": "Completed",
    "category": "Property",
    "tags": [
      "fundamental"
    ],
    "markdown": "In the context of computing, an abstraction is a representation that \nhides specifics from a consumer of [services](https://glossary.cncf.io/service/) \n(a consumer being a computer program or human), \nmaking a system more generic and thus easily understood. \nA good example is your laptop's operating system (OS). \nIt abstracts away all the details of how your computer works. \nYou don't need to know anything about CPU, memory, and how programs are handled, \nyou just operate the OS and the OS deals with the details. \nAll these details are hidden behind the OS \"curtain\" or abstraction. \n\nSystems typically have multiple abstraction layers. \nThis significantly simplifies development. \nWhen programming, developers build components compatible with a particular abstraction layer and \ndon't have to worry about all underlying specifics that can be very heterogeneous. \nIf it works with the abstraction layer, it works with the system \n— no matter what's under the hood. \n",
    "slug": "abstraction"
  }
]